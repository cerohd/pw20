<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Patrick Weaver: Blog</title>
  <subtitle></subtitle>
  <link href="https://patrickweaver.net/feed.xml" rel="self"/>
  <link href="https://patrickweaver.net/blog/"/>
  <updated>2022-08-18T00:00:00Z</updated>
  <id>https://patrickweaver.net/</id>
  <author>
    <name>Patrick Weaver</name>
    <email>hello.patrickw@gmail.com</email>
  </author>
  
  <entry>
    <title>How we used a chatbot to teach writing and coding!</title>
    <link href="https://patrickweaver.net/blog/how-we-used-a-chatbot-to-teach-writing-and-coding/"/>
    <updated>2016-06-15T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/how-we-used-a-chatbot-to-teach-writing-and-coding/</id>
    <content type="html">&lt;p&gt;When &lt;a href=&quot;https://mouse.org/&quot;&gt;Mouse&lt;/a&gt; moved into our new office in early 2015, we were excited to have space for our high school &lt;a href=&quot;https://mouse.org/mouse-design-league&quot;&gt;Design League&lt;/a&gt; program to spread out and work on assistive technology projects like &lt;a href=&quot;https://www.instagram.com/p/BGiUJ8awRJp/&quot;&gt;1derphone&lt;/a&gt;, a motorized headphone for a DJ with limited mobility. We also quickly realized we had the chance to reach more students in more ways by hosting flexible open events that any NYC students could attend.&lt;/p&gt;
&lt;p&gt;We hosted our first open &lt;a href=&quot;https://mouse.org/makernight&quot;&gt;Maker Night&lt;/a&gt; in March 2015 and it quickly became a space where students showed up and could work on anything creative and innovative. Every month, we saw new projects emerge from crafting, coding, and anything in between:&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*eku7Cc10Y9NSFAm7MP7tYA.jpeg&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/400/1*hA1_vnNXOvLg0WCWt6PluA.jpeg&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*ieyZhs_PDEsjWpTP8sDWaw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;
&lt;p&gt;Pictures from Maker Night at &lt;a href=&quot;http://mouse.org/&quot;&gt;Mouse&lt;/a&gt;&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;We often test ideas for new creative activities at Maker Nights and one new project I had been playing around with was &lt;a href=&quot;https://forest-noodle.glitch.me/&quot;&gt;a simple chatbot&lt;/a&gt; that students could remix. We love teaching any new tech skill through activities that are quick and easy to jump into and have created a few introduction to &lt;a href=&quot;https://zircon-porch.glitch.me/&quot;&gt;coding&lt;/a&gt; &lt;a href=&quot;https://distinct-zoo.glitch.me/&quot;&gt;activities&lt;/a&gt; using remixable JavaScript arrays (Check out a few of &lt;a href=&quot;https://automatic-triangle.glitch.me/&quot;&gt;Mouse‚Äôs Web Making activities&lt;/a&gt; created through our partnership with Mozilla).&lt;/p&gt;
&lt;p&gt;We usually have students start out by quickly &lt;a href=&quot;https://efficacious-hook.glitch.me/&quot;&gt;remixing the chatbot‚Äôs script&lt;/a&gt;: have the bot ask about your day, or give the chatbot a unique personality. Then they can move on to second level challenges: &lt;a href=&quot;https://smart-raincoat.glitch.me/&quot;&gt;remix the interface CSS&lt;/a&gt;, &lt;a href=&quot;https://possible-boot.glitch.me/&quot;&gt;teach the bot to repeat a user‚Äôs name back to them&lt;/a&gt;, or &lt;a href=&quot;https://obtainable-mosquito.glitch.me/&quot;&gt;teach the bot to respond to yes or no questions&lt;/a&gt;. All the linked examples are real student work, created between pizza slices at a Mouse Maker Night!&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*R7wDi-aaq56c6scszMkT9g.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*4frB9lA0wqCuoQMb_lLdHQ.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*B2IS5kkuK6FaQjmIsPJ3CA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;3 remixes of the chatbot&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I tried out the chatbot at our March Maker Night with a few students from &lt;a href=&quot;http://lespnyc.com/&quot;&gt;Lower East Side Prep&lt;/a&gt;. Many LESP students are recent immigrants and as their principal notes on their website, their ‚Äústudent body represents more than 50 countries including the United States.‚Äù I sat down with a few LESP students, showed them the basics of editing the script and they instantly started creating.&lt;/p&gt;
&lt;p&gt;Students who were shy to get started or were nervous that they had never coded before were able to get familiar by creating linear scripts that anticipated a user‚Äôs responses or building in simple logic. One student who had recently moved to the U.S. created a bot that &lt;a href=&quot;https://lucky-bassoon.glitch.me/&quot;&gt;empathized with people who miss faraway friends&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Something about the narrative and engaging interface of a bot made students want to iterate on their designs. Two students would write a bot script, then switch and play each other‚Äôs bots. They would start by focusing on writing a friendly personality, then dive into a challenge like the bot learning a user‚Äôs name or a place name.&lt;/p&gt;
&lt;p&gt;Moments like these are exactly what Mouse strives to create with technology focused youth development curriculum. We love seeing language arts students publish writing online and code their own websites, history students create a &lt;a href=&quot;https://www.youtube.com/watch?v=5D1iIEb49lE&quot;&gt;Serious Game&lt;/a&gt; about the civil rights movement, or science students make DIY Batteries to learn &lt;a href=&quot;https://www.youtube.com/watch?v=nofdW8nARTg&quot;&gt;Green Tech&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;üì† Interested in learning more about Mouse? Email &lt;a href=&quot;mailto:info@mouse.org&quot;&gt;info@mouse.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;üèÖ Check out the &lt;a href=&quot;http://makernighthalloffame.tumblr.com/&quot;&gt;Maker Night Hall of Fame on Tumblr&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;üóΩ In the NYC area and interested in attending a Mouse Maker Night?&lt;/strong&gt; &lt;a href=&quot;http://mouse.org/makernight&quot;&gt;Sign up&lt;/a&gt; for our next Maker Night on &lt;strong&gt;June 30 from 4pm to 6pm&lt;/strong&gt;!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Which Wearable Arduino Should I Use For My Sewable Tech Project?</title>
    <link href="https://patrickweaver.net/blog/which-wearable-arduino-should-i-use-for-my-sewable-tech-project/"/>
    <updated>2017-09-29T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/which-wearable-arduino-should-i-use-for-my-sewable-tech-project/</id>
    <content type="html">&lt;p&gt;This fall &lt;a href=&quot;https://medium.com/@mouse_org&quot;&gt;Mouse&lt;/a&gt; (&lt;a href=&quot;http://mouse.org/&quot;&gt;mouse.org&lt;/a&gt;) launched our brand new &lt;a href=&quot;https://mouse.org/mouse-courses&quot;&gt;Sewable Tech Course&lt;/a&gt;! The course introduces learners to circuitry and electronics without the abstraction of a breadboard. In the final two projects in the course we use a wearable Arduino to prototype a DIY activity tracker.&lt;/p&gt;
 &lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*gfNKPipgo0Yp_bZLJLg7MQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;Sew-matic for DIY Wearable Goal Tracker from Mouse Create&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The big question we ran into when I was helping my colleague &lt;a href=&quot;https://twitter.com/katermouse&quot;&gt;Kate&lt;/a&gt; prototype the course was, which wearable Arduino to use. Along the way we tested 7 Arduino compatible microcontrollers and settled on recommending a &lt;a href=&quot;https://www.sparkfun.com/products/12049&quot;&gt;LilyPad Arduino USB&lt;/a&gt;, but there are advantages to each of the Arduinos we tested and different kinds projects would benefit from including each of them.&lt;/p&gt;
 &lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*nxNOfE_aAIHrgXcgX8GSLQ.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;Our collection of wearable arduinos&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.sparkfun.com/products/12049&quot;&gt;Sparkfun LilyPad Arduino USB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.ebay.com/sch/i.html?_nkw=LilyPad+Arduino+USB+ATmega32U4&quot;&gt;Generic LilyPad Arduino USB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.adafruit.com/product/659&quot;&gt;Adafruit FLORA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.ebay.com/sch/i.html?_nkw=LilyTiny&quot;&gt;Generic LilyTiny&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.adafruit.com/product/2470&quot;&gt;Arduino GEMMA&lt;/a&gt; (Discontinued)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.adafruit.com/product/1222&quot;&gt;Adafruit GEMMA v2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.adafruit.com/product/3501&quot;&gt;Adafruit GEMMA M0&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of the boards work with the &lt;a href=&quot;https://www.arduino.cc/en/Main/Software&quot;&gt;Arduino IDE&lt;/a&gt; (most with some extra steps), are roughly circular, and most run on 3.3 Volts, but there are slight differences that make certain boards better for some types of projects.&lt;/p&gt;
&lt;h4&gt;[1] &amp;amp; [2] Sparkfun/Generic LilyPad Arduino USB&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*FWirsLamzgR-H2Wbht2ZYg.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[1] From &lt;a href=&quot;https://www.sparkfun.com/products/12049&quot;&gt;Sparkfun: $25&lt;/a&gt;, [2] &lt;a href=&quot;https://www.ebay.com/sch/i.html?_nkw=LilyPad+Arduino+USB+ATmega32U4&quot;&gt;Generic: $6 to $20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5 Digital Pins&lt;/li&gt;
&lt;li&gt;4 Analog Pins&lt;/li&gt;
&lt;li&gt;Onboard LED (D13)&lt;/li&gt;
&lt;li&gt;On/Charge Switch and Reset Button&lt;/li&gt;
&lt;li&gt;JST battery connector&lt;/li&gt;
&lt;li&gt;2&amp;quot;/5 cm&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.arduino.cc/en/Reference/Serial&quot;&gt;Supports Serial Communication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The LilyPad Arduinos are the only boards on this list that work with the Arduino IDE without any extra steps, this is the main reason why we recommend this board on Mouse Create. If this board will be your first experience with Arduino or you will need a few analog pins the LilyPad would be a great choice.&lt;/p&gt;
&lt;p&gt;The SparkFun model costs a bit more but a portion of the sales go to &lt;a href=&quot;http://leahbuechley.com/&quot;&gt;Leah Buechley&lt;/a&gt; to support open source e-textiles and e-textiles education development.&lt;/p&gt;
&lt;p&gt;Be careful when buying to get the LilyPad Arduino USB if you need a USB connection. The original &lt;a href=&quot;https://www.sparkfun.com/products/13342&quot;&gt;LilyPad Arduino 328 Main Board&lt;/a&gt; (not pictured), requires an FTDI connection to upload code (but that one has more pins!).&lt;/p&gt;
&lt;h4&gt;[3] Adafruit FLORA&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*WOH8dSMPKiHUzYIAU4WerQ.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From &lt;a href=&quot;https://www.adafruit.com/product/659&quot;&gt;Adafruit $15&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8 Digital Pins&lt;/li&gt;
&lt;li&gt;4 Analog Pins (D6, D9, D10, D12)&lt;/li&gt;
&lt;li&gt;Onboard LED (D7), Onboard RGB LED (D8)&lt;/li&gt;
&lt;li&gt;On/Off Switch and Reset Button&lt;/li&gt;
&lt;li&gt;JST battery connector&lt;/li&gt;
&lt;li&gt;1.75&amp;quot;/4.5 cm&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.arduino.cc/en/Reference/Serial&quot;&gt;Supports Serial Communication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Adafruit Flora is a great board and can handle any project. It‚Äôs smaller than the LilyPad but has 3 more pins, and the onboard RGB LED is very useful as a Hello, World. The only drawback to this board is &lt;a href=&quot;https://learn.adafruit.com/add-boards-arduino-v164/overview&quot;&gt;adding the board in the Arduino IDE&lt;/a&gt; and installing the &lt;a href=&quot;https://learn.adafruit.com/adafruit-arduino-ide-setup/windows-driver-installation&quot;&gt;Adafruit drivers on Windows&lt;/a&gt;, but both of these are one-time steps and don‚Äôt take more than a few minutes. We did have some issues uploading code via a USB 3.0 port, but this can be avoided by using a USB 2.0 hub.&lt;/p&gt;
&lt;h4&gt;[4] Generic LilyTiny&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*6Cx0oeFjZ0aGB6ek2vzCtQ.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.ebay.com/sch/i.html?_nkw=LilyTiny&quot;&gt;Generic $2 to $5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6 Digital Pins&lt;/li&gt;
&lt;li&gt;Onboard LED (D1)&lt;/li&gt;
&lt;li&gt;1&amp;quot;/2.5 cm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We found this board when researching and thought it might be useful for large groups with a limited budget to give every learner a board. This board has two easy to recognize advantages, it is both the smallest and the least expensive board on this list. The disadvantages are a little bit harder to spot so if you are thinking of using this board with a large group I would buy one to test with first.&lt;/p&gt;
&lt;p&gt;This board is the only one on this list that does not have alligator clip friendly pins. When testing we were still able to attach alligator clips, but it is easy to accidentally clip two pins and create a short circuit. This board also lacks both an on/off switch and a JST battery connector which means it has to be powered via USB or the 5V pin (this is the only board on this list that runs on 5V).&lt;/p&gt;
&lt;p&gt;The biggest disadvantage of this board is the upload process. &lt;a href=&quot;https://digistump.com/wiki/digispark/tutorials/connecting&quot;&gt;Following these instructions&lt;/a&gt;, we had to add the board to the Arduino IDE, install Digistump drivers, and hit the plug in the board to USB at a specific point in the process. We also had issues with this board on USB 3.0 ports.&lt;/p&gt;
&lt;p&gt;If you have a lot of experience with Arduino or have a very small budget but a lot of patience this board might be for you.&lt;/p&gt;
&lt;h4&gt;[5] &amp;amp; [6] Arduino GEMMA and Adafruit GEMMA v2&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*MyLI2jE1Oo2yA6sYbYQKCA.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[6] From &lt;a href=&quot;https://www.adafruit.com/product/1222&quot;&gt;Adafruit $10&lt;/a&gt;, [5] From &lt;a href=&quot;https://www.adafruit.com/product/2470&quot;&gt;Adafruit (Discontinued)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3 Digital Pins&lt;/li&gt;
&lt;li&gt;1 Analog Pin (D2)&lt;/li&gt;
&lt;li&gt;Onboard LED (D1)&lt;/li&gt;
&lt;li&gt;On/Off Switch and Reset Button&lt;/li&gt;
&lt;li&gt;JST battery connector&lt;/li&gt;
&lt;li&gt;1.25&amp;quot;/2.75 cm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both of these boards (along with the Gemma M0) are manufactured by Adafruit, and are visually and functionally very similar. The Arduino Gemma is teal and has the Adafruit logo on the back, the Adafruit Gemma v2 is black and has the Adafruit logo on the front. Both have an ATtiny85 chip that does not support serial communication.&lt;/p&gt;
&lt;p&gt;Both the Gemma boards are great small wearable Arduinos. The small number of pins and small size make this board very approachable for a beginner, and would make the perfect tool for a simple sewable tech project. We initially were going to recommend the Adafruit Gemma v2 on Mouse Create, but we had enough &lt;a href=&quot;https://learn.adafruit.com/introducing-gemma/about-the-bootloader&quot;&gt;issues with uploading via USB 3.0&lt;/a&gt; that instead of shipping a USB 2.0 hub along with the boards we decided to opt for the LilyPad.&lt;/p&gt;
&lt;p&gt;If you already have a USB 2.0 hub or computers with USB 2.0 ports this board will work great. It does not have serial communication so it is best suited for simpler projects. Like the Adafruit Flora you will have to &lt;a href=&quot;https://learn.adafruit.com/add-boards-arduino-v164/overview&quot;&gt;add the board to the Arduino IDE&lt;/a&gt; and &lt;a href=&quot;https://learn.adafruit.com/adafruit-arduino-ide-setup/windows-driver-installation&quot;&gt;install the Adafruit drivers on Windows&lt;/a&gt; (for the Gemma V2).&lt;/p&gt;
&lt;h4&gt;[7] Adafruit GEMMA M0&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*Qyf4eRy8XKT-_OwYjHu9xw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From &lt;a href=&quot;https://www.adafruit.com/product/3501&quot;&gt;Adafruit $10&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3 Digital Pins&lt;/li&gt;
&lt;li&gt;3 Analog Pins (D0, D1, D2)&lt;/li&gt;
&lt;li&gt;Onbaord LED (D13), Onboard RGB LED (D?)&lt;/li&gt;
&lt;li&gt;On/Off Switch and Reset Button&lt;/li&gt;
&lt;li&gt;JST battery connector&lt;/li&gt;
&lt;li&gt;1.25&amp;quot;/2.75 cm&lt;/li&gt;
&lt;li&gt;Supports &lt;a href=&quot;https://www.arduino.cc/en/Reference/Serial&quot;&gt;Serial Communication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Supports &lt;a href=&quot;https://blog.adafruit.com/2017/01/09/welcome-to-the-adafruit-circuitpython-beta/&quot;&gt;Circuit Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Adafruit GEMMA M0 was released just as we were finishing up our Sewable Tech course, a little too late to include in the kits we were putting together, but I still highly recommend this board. The Gemma M0 does everything the older Gemmas can and a lot more. I haven‚Äôt had any issues with USB 3.0 using this board, and the ATSAMD21E18 chip supports serial communication.&lt;/p&gt;
&lt;p&gt;The big step forward with the Gemma M0 and the reason Mouse might include this board in future kits is &lt;a href=&quot;https://blog.adafruit.com/2017/01/09/welcome-to-the-adafruit-circuitpython-beta/&quot;&gt;Circuit Python&lt;/a&gt;. A frequent question from schools interested in circuitry and electronics and sewable tech is ‚ÄúWill this Arduino work with my Chromebook?‚Äù Until now the answer has always been no (though the &lt;a href=&quot;https://www.arduino.cc/en/Main/Software&quot;&gt;online Arduino IDE&lt;/a&gt; now works with Arduino Uno).&lt;/p&gt;
&lt;p&gt;Circuit Python allows you to use the Gemma M0 to bypass the Arduino IDE completely (but still works with the IDE if you prefer that). The board will show up as a drive when you plug it in to your computer (yes, even a Chromebook), and adding the following code to a file called &lt;code&gt;code.py&lt;/code&gt; will produce the familiar ‚ÄúBlink‚Äù Hello, World example.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import digitalio
import board
import time
led = digitalio.DigitalInOut(board.D13)
led.direction = digitalio.Direction.OUTPUT
while True:
    led.value = not led.value
    time.sleep(0.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with other Adafruit Boards if you are using the Arduino IDE instead of Python you will have to &lt;a href=&quot;https://learn.adafruit.com/add-boards-arduino-v164/overview&quot;&gt;add the board to the IDE&lt;/a&gt; and &lt;a href=&quot;https://learn.adafruit.com/adafruit-arduino-ide-setup/windows-driver-installation&quot;&gt;install the Adafruit drivers on Windows&lt;/a&gt;. You may also have to &lt;a href=&quot;https://learn.adafruit.com/adafruit-gemma-m0/circuitpython&quot;&gt;reinstall Circuit Python&lt;/a&gt; if you go back and forth between the IDE and Circuit Python, but this is a simple drag and drop process. I‚Äôm also not sure how to control the RGB LED but I haven‚Äôt spent much time trying to figure it out.&lt;/p&gt;
&lt;p&gt;All the boards we tested worked great once we figured out the tricks of each and any will work for most sewable tech projects. Once you decide on a board, check out &lt;a href=&quot;https://mouse.org/work&quot;&gt;Mouse Create&lt;/a&gt; to find some fun projects!&lt;/p&gt;
 &lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*dNpQjlUdHIzaTusjw9ERRw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;
&lt;p&gt;Making a light up phone case at &lt;a href=&quot;https://medium.com/@mouse_org&quot;&gt;Mouse&lt;/a&gt; &lt;a href=&quot;https://mouse.org/makernight&quot;&gt;Maker Night&lt;/a&gt;&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;</content>
  </entry>
  
  <entry>
    <title>Building a futuristic Record Player with Glitch and Raspberry Pi</title>
    <link href="https://patrickweaver.net/blog/building-a-futuristic-record-player-with-glitch-and-raspberry-pi/"/>
    <updated>2018-10-23T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/building-a-futuristic-record-player-with-glitch-and-raspberry-pi/</id>
    <content type="html">&lt;p&gt;Earlier this year I wanted to explore the new &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/async_function&quot;&gt;async/await&lt;/a&gt; functionality in Javascript so I started playing around with &lt;a href=&quot;https://async-await-machine.glitch.me/&quot;&gt;a project&lt;/a&gt; on Glitch (&lt;a href=&quot;https://glitch.com/&quot;&gt;glitch.com&lt;/a&gt;) that would call one API after another, then generate new API call options from each cycle. I compiled a long list of potential APIs to use, but didn‚Äôt get past chaining together an &lt;a href=&quot;https://dog.ceo/dog-api/&quot;&gt;API that will respond with a picture of a specific breed of dog&lt;/a&gt;, and the &lt;a href=&quot;https://www.mediawiki.org/wiki/API:Main_page&quot;&gt;Wikipedia API&lt;/a&gt; which could respond with the pages that came up in a search for the name of the breed.&lt;/p&gt;
&lt;figure&gt;
&lt;div class=&quot;glitch-embed-wrap&quot; style=&quot;height: 420px; width: 100%;&quot;&gt;
  &lt;iframe allow=&quot;geolocation; microphone; camera; midi; encrypted-media&quot; src=&quot;https://glitch.com/embed/#!/embed/async-await-machine?path=README.md&amp;previewSize=100&quot; alt=&quot;async-await-machine on Glitch&quot; style=&quot;height: 100%; width: 100%; border: 0;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;figcaption&gt;A Glitch embed of my Dog ‚Üí Wikipedia API prototype: click on the name of a dog and you will get a picture of that dog, and a list of pages linked from that dog‚Äôs Wikipedia page.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I started exploring what other APIs I could connect and realized that most of them seemed to enforce a relatively strict internal type system. Even from the many connections Wikipedia could provide it was hard to think of a potential next link that would always match up with the mishmash Wikipedia returned. While it might be easy to match up the Google Maps API to a weather API, connecting more abstract concepts was much more difficult.&lt;/p&gt;
&lt;h2&gt;The ‚ÄòRecord Player‚Äô app&lt;/h2&gt;
&lt;p&gt;While thinking through this an idea jumped out at me. I could connect the Google Vision API to Spotify to find albums based on pictures of a record cover. The idea seemed so obvious that I figured someone else had already done it (with more thorough research later I found a few similar projects but none that were fully implemented).&lt;/p&gt;
&lt;p&gt;I decided that this spark of an idea was already a lot more interesting than my infinite API art project, but it still had the Rube Goldberg-esque quality I was going for. Even so, I still might have abandoned it without a tool like Glitch, which to me says, ‚Äúyour wacky idea is worth making (and it won‚Äôt take very long).‚Äù Using the skeleton of my previous project, I was able to put together (in about an hour) an app that bounced an image off of the Google Vision API then brought up search results from Spotify. I sent it to a friend who works at Spotify, and when she confirmed that it didn‚Äôt already exist I decided to spend a few hours putting together a more polished version (the hardest part turned out to be drag and drop file upload).&lt;/p&gt;
&lt;p&gt;Thanks to Glitch‚Äôs embed feature you can take a look at the app (and the code!) below:&lt;/p&gt;
&lt;figure&gt;
&lt;div class=&quot;glitch-embed-wrap&quot; style=&quot;height: 420px; width: 100%;&quot;&gt;
  &lt;iframe allow=&quot;geolocation; microphone; camera; midi; encrypted-media&quot; src=&quot;https://glitch.com/embed/#!/embed/record-player?path=README.md&amp;previewSize=100&quot; alt=&quot;record-player on Glitch&quot; style=&quot;height: 100%; width: 100%; border: 0;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;figcaption&gt;A Glitch embed of the Record Player app&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The ‚Äòfinal‚Äô version of the project, ‚Äú&lt;a href=&quot;http://record-player.glitch.me/&quot;&gt;Record Player&lt;/a&gt;‚Äù was surprisingly simple. When given a reasonably well lit image of an even somewhat popular album the Google Vision API is able to identify the name of the album (occasionally just the artist). There were a few words I hard coded to ignore (things like ‚Äúvinyl‚Äù, ‚Äúcd‚Äù, or ‚Äúimport‚Äù), but other than that I was able to send Google Vision‚Äôs ‚Äúbest guess‚Äù to Spotify, and play the first result. I designed a goofy front end (with every music related emoji) and shared it on Twitter thinking that a few people would try it.&lt;/p&gt;
&lt;figure&gt;
&lt;div class=&quot;glitch-embed-wrap&quot; style=&quot;height: 420px; width: 100%;&quot;&gt;
  &lt;iframe allow=&quot;geolocation; microphone; camera; midi; encrypted-media&quot; src=&quot;https://glitch.com/embed/#!/embed/record-player?path=censoredWords.js&amp;previewSize=0&quot; alt=&quot;record-player on Glitch&quot; style=&quot;height: 100%; width: 100%; border: 0;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;figcaption&gt;A Glitch embed with my surprisingly short list of censored words&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/anildash/&quot;&gt;Anil Dash&lt;/a&gt; unexpectedly shared, and quickly it it started showing up &lt;a href=&quot;https://pitchfork.com/news/new-app-is-basically-shazam-for-album-covers/&quot;&gt;in&lt;/a&gt; &lt;a href=&quot;https://www.pastemagazine.com/articles/2018/05/new-app-automatically-recognizes-album-covers.html&quot;&gt;a&lt;/a&gt; &lt;a href=&quot;https://www.nme.com/news/music/app-album-cover-shazam-2306795&quot;&gt;lot&lt;/a&gt; &lt;a href=&quot;https://www.engadget.com/2018/05/04/record-player-app-image-based-spotify-search/&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://www.altpress.com/news/app_matches_album_covers_spotify/&quot;&gt;strange&lt;/a&gt; &lt;a href=&quot;https://www.androidauthority.com/record-player-spotify-google-861977/&quot;&gt;corners&lt;/a&gt; &lt;a href=&quot;https://www.rollingstone.it/musica/news-musica/ora-esiste-uno-shazam-per-le-copertine-degli-album/410773/&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://lifehacker.com/stream-a-vinyl-album-by-snapping-a-pic-of-its-cover-art-1825800020&quot;&gt;the&lt;/a&gt; &lt;a href=&quot;https://www.thecurrent.org/feature/2018/05/02/app-album-covers&quot;&gt;internet&lt;/a&gt;. I was flattered by the coverage, but a few people were pointing out, ‚Äúwhy would you take a picture instead of just typing in the name of the album?‚Äù First of all, it‚Äôs fun, which should be reason enough. But beyond that, there‚Äôs really no reason to right now, there are too many barriers and restrictions in place in the tools we use every day like Spotify and Google, that making a mashup like this will usually require an engineer instead of just an imagination.&lt;/p&gt;
&lt;h2&gt;Getting Record Player working on a Raspberry Pi&lt;/h2&gt;
&lt;p&gt;From the beginning I wanted to create a physical version of Record Player (inspired by the amazing things they seem to be doing at &lt;a href=&quot;https://dynamicland.org/&quot;&gt;Dynamicland&lt;/a&gt; without ‚Äútraditional‚Äù input and output devices). It would be a machine that could detect when you put a record cover in front of it, and automatically start playing the first song. No screens, no searching, no curated playlist to distract from the physical thing in my hands.&lt;/p&gt;
&lt;p&gt;For the second time I was pleasantly surprised that by finding the right tools, a proof of concept was much easier than I expected. Using a Raspberry Pi with a camera module attached made a simple way to capture images. This left only the challenge of identifying when to start playing music. At first I thought that this might be easy to do by taking advantage of Google‚Äôs advanced image processing again, but I realized that the cost of the Google Vision API queries (you only get a certain amount free per month) would be prohibitive if I wanted the device to respond automatically.&lt;/p&gt;
&lt;p&gt;I decided to see if a simple algorithm running on the Raspberry Pi could identify when something new was placed in front of the camera, which seemed to work well enough. Connecting this to a slightly modified version of the Node.js server that runs the original Record Player Glitch app created exactly the machine I had imagined. The video below shows my ‚ÄúRecord Player‚Äù automatically starting playback when it sees a record cover. This prototype has screens, but they‚Äôre only used to start the app and troubleshoot.&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/288443309&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;A video of the Record Player machine running on a Raspberry Pi&lt;/p&gt;
&lt;p&gt;Anil‚Äôs suggestion for using ‚ÄúRecord Player‚Äù when he shared the Glitch app, was to see what song came up when you take a selfie, or ‚ÄúShazam for your face‚Äù as he put it. Of course this was hilarious, and this is the kind of play and dynamic interactions that can happen when we start to break down the strict parameters and physical barriers that currently constrain our interactions with technology.&lt;/p&gt;
&lt;p&gt;Browsing Spotify is infinitely less interesting than browsing a friend‚Äôs record collection, but the convenience of any song ever recorded will usually win over the joy of discovering something unexpected. If we want this kind of ‚Äòmagic‚Äô to bring technology like Google Vision out of prepackaged apps in our phones and laptops we need to allow for new ways of communicating with computers, and each other, that allow for experimentation, weirdness and imagination.&lt;/p&gt;
&lt;p&gt;When we start to join the interesting parts of the real world (for example: everything created before 1997) with the conveniences that smartphones have brought we can start to imagine dynamic digital experiences like the analog ones we have thought up for hundreds of years. Vinyl records themselves were designed as a static medium, but creative musicians saw a way to interact and started sampling and scratching them to create hip-hop.&lt;/p&gt;
&lt;p&gt;The idea for ‚ÄúRecord Player‚Äù only seemed obvious to me after a few hours of sifting through documentation for dozens of APIs. As users we can‚Äôt see the ‚Äúshape‚Äù of the internet, but these shapes determine what we can and can‚Äôt do, what we can and can‚Äôt imagine is possible. Surely every search on a weather or maps app is a city or address, almost all searches on Google Images are for nouns, and every search on Spotify or Genius is for an artist or song. But try connecting these services and APIs along unusual angles and you will start running into walls.&lt;/p&gt;
&lt;p&gt;Throw a song at Google Maps to see where it was recorded? Pass a Yelp page to the New York Times API to find any news about the neighborhood? These queries might be possible, but they almost always require diving into the nitty gritty of several APIs, and massaging the data to make the connection. In today‚Äôs world ideas like ‚ÄúRecord Player‚Äù have to be a million dollar business to be worth doing. Many articles written about the Record Player app implied that Spotify had made it. The way that we experience modern technology tells us that only huge corporations are able to create new ways of experiencing the world.&lt;/p&gt;
&lt;p&gt;Products like &lt;a href=&quot;https://glitch.com/&quot;&gt;Glitch&lt;/a&gt;, &lt;a href=&quot;https://www.raspberrypi.org/&quot;&gt;Raspberry Pi&lt;/a&gt;, &lt;a href=&quot;https://ifttt.com/&quot;&gt;IFTTT&lt;/a&gt;, &lt;a href=&quot;https://support.apple.com/guide/shortcuts/welcome/ios&quot;&gt;Shortcuts&lt;/a&gt;, and the inspiration for the Raspberry Pi Record Player, &lt;a href=&quot;https://dynamicland.org/&quot;&gt;Dynamicland&lt;/a&gt; make a more interesting and open future seem possible, now we just need to build the rest of it.&lt;/p&gt;
&lt;p&gt;Start now by remixing Record Player on Glitch:
&lt;a href=&quot;https://glitch.com/~record-player&quot;&gt;https://glitch.com/~record-player&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Or make your own Raspberry Pi powered version:
&lt;a href=&quot;https://github.com/patrickweaver/record-player-rpi&quot;&gt;https://github.com/patrickweaver/record-player-rpi&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>I Could Never Remember How to Make a Simple S3 Upload Feature So I Wrote It Down</title>
    <link href="https://patrickweaver.net/blog/i-could-never-remember-how-to-make-a-simple-s3-upload-feature-so-i-wrote-it-down/"/>
    <updated>2020-04-21T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/i-could-never-remember-how-to-make-a-simple-s3-upload-feature-so-i-wrote-it-down/</id>
    <content type="html">&lt;p&gt;Whenever I start a new web project there is an ominous, literal, figurative, &amp;quot;cloud&amp;quot; lurking on the horizon: Will this project get complicated enough to need to be connected to S3 for file upload?&lt;/p&gt;
&lt;p&gt;More often than I&#39;d like the answer is yes, and at this point I&#39;ve re-learned how to connect a Node.js app to S3 more times than I&#39;d like. Rather than keep learning just enough S3 to get a project working, and then instantly forgetting it, I decided to write the process down so I can follow my own instructions.&lt;/p&gt;
&lt;p&gt;I&#39;m sure this will also find its way to people who know more than I do and might be able to alert me to anything I&#39;m doing wrong. If this is you, &lt;a href=&quot;https://twitter.com/patrickweave_r&quot;&gt;please reach out&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;Setting Up AWS Authentication&lt;/h2&gt;
&lt;p&gt;Connecting an app isn&#39;t usually the most difficult part of setting up S3. Where I always have to go back to documentation is setting up user and bucket permissions correctly. When I first started using S3 around 2013 a common recommendation was to just set buckets to public and link to objects directly. More recently though, many people (including Amazon), recommend not making buckets public.&lt;/p&gt;
&lt;p&gt;In my experience, it&#39;s best to create both a user and a policy when setting up AWS permissions. The keys you will use in your app will be associated with the user, and the permissions you want your user to have will be associated with the policy. This way, if your credentials are compromised you can create a new user, and all you have to do is add the policy to the new user.&lt;/p&gt;
&lt;p&gt;I&#39;ve also found it&#39;s a best practice to create a new bucket for each of the small apps that I make. If you&#39;re working on a bigger project or want to set up a general purpose place to upload you may want to do this differently, but creating a unique bucket and user for each project helps me keep an eye on things, and not worry too much about credentials getting compromised. Because I only need one bucket for my app it&#39;s easier to create it in the AWS web interface than to build functionality to create buckets into my app.&lt;/p&gt;
&lt;h4&gt;Creating a Bucket&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Log into AWS and click on &amp;quot;Services&amp;quot; in the top left. Select &amp;quot;S3&amp;quot; in the &amp;quot;Storage&amp;quot; section, then click on &amp;quot;Create Bucket&amp;quot; on the main S3 screen.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/wzb11or02x3fgsdlobl1.png&quot; alt=&quot;A screenshot of the main S3 screen&quot; /&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Give your bucket a name (this will be visible to users so something related to your app is best), and select a region (probably whichever is closest to your users), leave &amp;quot;Block all public access&amp;quot; checked, then click &amp;quot;Create bucket&amp;quot;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/jqobhso6ba8idwecff7l.png&quot; alt=&quot;A screenshot of the Create bucket screen&quot; /&gt;&lt;/p&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;Note your bucket name (probably in an ENV variable), it&#39;s now ready to receive uploads!&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Creating a Policy&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Click on your name in the top right. In the dropdown select &amp;quot;My Security Credentials&amp;quot;, then in the &amp;quot;Identity and Access Management (IAM)&amp;quot; sidebar on the left, click on &amp;quot;Policies&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on the &amp;quot;Create policy&amp;quot; button. There are 2 ways to give your policy permissions, with the Visual Editor, and with JSON. We&#39;ll use the Visual Editor here, but you can probably just pate the JSON at the end with minor edits.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Visual Editor has 4 sections: Service, Actions, Resources, and Request Conditions. Start in Service and click on S3.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You want to add 3 specific actions: &amp;quot;PutObject&amp;quot; which allows uploading files, &amp;quot;GetObject&amp;quot; which allows reading files, and &amp;quot;DeleteObject&amp;quot; (I think you can figure this one out). &amp;quot;GetObject&amp;quot; is in the &amp;quot;Read&amp;quot; section, check the checkbox there. &amp;quot;PutObject&amp;quot; and &amp;quot;DeleteObject&amp;quot; are both in the &amp;quot;Write&amp;quot; section. At the end you should have 3 objects selected:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/xq9fza7qlzaxb9s2uwxx.png&quot; alt=&quot;A screenshot of the Create Policy actions selection&quot; /&gt;&lt;/p&gt;
&lt;ol start=&quot;5&quot;&gt;
&lt;li&gt;In the Resources section click on &amp;quot;Add ARN&amp;quot;, then fill in your Bucket Name, and click on &amp;quot;Any&amp;quot; for Object name. This means that users with this policy can only perform the actions above on one bucket, but can perform those actions on any of the objects in that bucket.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/n99mhoauau96yg2fp6j2.png&quot; alt=&quot;A screenshot of the Add ARN screen when creating a policy&quot; /&gt;&lt;/p&gt;
&lt;ol start=&quot;6&quot;&gt;
&lt;li&gt;If you click over to the JSON editor you should see the code below. You can also just copy this in. Note that you should edit the &amp;quot;Resource&amp;quot; property to have your actual bucket name:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
    &amp;quot;Statement&amp;quot;: [
        {
            &amp;quot;Sid&amp;quot;: &amp;quot;VisualEditor0&amp;quot;,
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;s3:PutObject&amp;quot;,
                &amp;quot;s3:GetObject&amp;quot;,
                &amp;quot;s3:DeleteObject&amp;quot;
            ],
            &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::YOUR_BUCKET_NAME/*&amp;quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&quot;6&quot;&gt;
&lt;li&gt;Click on &amp;quot;Review policy&amp;quot;, then give your policy a name and a description. Then click &amp;quot;Create policy&amp;quot;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Creating a User&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Click on Users in the left sidebar, then the &amp;quot;Add user&amp;quot; button at the top of the screen, give your user a name and select the checkbox for &amp;quot;Programmatic Access&amp;quot;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/gi90azo1auvxzjdbamyz.png&quot; alt=&quot;A screenshot of the Add User screen&quot; /&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;
&lt;p&gt;In the &amp;quot;Set permissions&amp;quot; section at the top of the page, click on &amp;quot;Attach existing policies directly&amp;quot;. Search for the policy you just created, then select it and click &amp;quot;Next: Tags&amp;quot;. You can skip Tags, and click &amp;quot;Next: Review&amp;quot;, then click &amp;quot;Create user&amp;quot;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You will now save your user&#39;s credentials. This is the only time you will be able to do this, so make sure you save them somewhere safe. You will also need to add the credentials as ENV variables in your app. I recommend clicking the &amp;quot;Download .csv&amp;quot; button and saving the file, at least until you get your app set up.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/3rqbznl2dlvif555eorn.png&quot; alt=&quot;A screenshot of the attach policy section of the create user screen&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;A simple example app&lt;/h2&gt;
&lt;p&gt;Congratulations! You are done with the AWS setup, now you can work on your app. I have a simple and heavily commented &lt;a href=&quot;https://aws-s3-example.glitch.me/&quot;&gt;example app&lt;/a&gt; I use to add this functionality to new projects:&lt;/p&gt;
&lt;!-- Copy and Paste Me --&gt;
&lt;div class=&quot;glitch-embed-wrap&quot; style=&quot;height: 420px; width: 100%;&quot;&gt;
  &lt;iframe src=&quot;https://glitch.com/embed/#!/embed/aws-s3-example?path=package.json&amp;previewSize=100&quot; title=&quot;aws-s3-example on Glitch&quot; allow=&quot;geolocation; microphone; camera; midi; vr; encrypted-media&quot; style=&quot;height: 100%; width: 100%; border: 0;&quot;&gt;
  &lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;The app is a Node.js app using Express. It uses 3 additional packages. &lt;a href=&quot;https://patrickweaver.net/blog/i-could-never-remember-how-to-make-a-simple-s3-upload-feature-so-i-wrote-it-down/aws-sdk&quot;&gt;https://www.npmjs.com/package/aws-sdk&lt;/a&gt; adds functionality to communicate with S3, &lt;a href=&quot;https://patrickweaver.net/blog/i-could-never-remember-how-to-make-a-simple-s3-upload-feature-so-i-wrote-it-down/uuid&quot;&gt;https://www.npmjs.com/package/uuid&lt;/a&gt; is used for object names in S3, and [https://www.npmjs.com/package/multer]multer is used to process file upload to the server before passing it to S3.&lt;/p&gt;
&lt;p&gt;The index page is a plain HTML file, but there are two POST routes in server.js: &lt;code&gt;/upload-image-form&lt;/code&gt; and &lt;code&gt;/upload-image-async&lt;/code&gt;. The two routes are mostly the same, but are repeated for easy copying.&lt;/p&gt;
&lt;p&gt;Lines 1 through 24 of server.js are setting up the dependencies:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;// The regular Node/Express stuff:
const express = require(&#39;express&#39;);
const app = express();
app.use(express.static(&#39;public&#39;));

// I will use the UUID package for s3 file names
const { v4: uuidv4 } = require(&#39;uuid&#39;);

// The AWS functionality is isolated for clarity:
const aws = require(&#39;./aws.js&#39;);

// Multer processes the file in the request body
// This allows one file to be uploaded at a time.
var multer = require(&#39;multer&#39;);

var memoryStorage = multer.memoryStorage();
var memoryUpload = multer({
	storage: memoryStorage,
	limits: {
		fileSize: 4*1024, // 4KB filesize limit
    //fileSize: 10*1024*1024, // 10 Mb filesize limit
		files: 1
	}
}).single(&#39;file&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The uploading to S3 happens in the two POST routes, and in an isolated &lt;code&gt;aws&lt;/code&gt; module. I will go through the regular HTML form route here, but the JS API endpoint route is mostly the same.&lt;/p&gt;
&lt;p&gt;The route uses the previously defined &lt;code&gt;memoryUpload&lt;/code&gt; to capture a file object in req.body.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;app.post(&#39;/upload-image-form&#39;, memoryUpload, async function(req, res) {
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we create an object to send to the &lt;code&gt;aws&lt;/code&gt; module (this is custom to this app, not the &lt;code&gt;aws-sdk&lt;/code&gt; npm package) with req.file. Most of the code below is comments, but the short version of what we need to send to the aws is an object with the properties &lt;code&gt;file&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt;. &lt;code&gt;file&lt;/code&gt; is the contents of the file, &lt;code&gt;id&lt;/code&gt; is what the file will be called in our AWS bucket:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;    const file = req.file;
    
    /*
    The file object has the following fields:
    
    fieldname: &#39;file&#39; // This was specified in the file input field in the HTML
    originalname:     // The original name of the file
    encoding:         // The encoding of the file, don&#39;t worry about
                         this unless you want to look at the bytes.
    mimetype:         // This will tell you what the filetype is, even if there
                         is no extension, or if it&#39;s wrong.
    buffer:           // This is the actual data from the file
    size:             // Only some files will have this, the file&#39;s size in bytes
    */
    
    
    // This is optional, but a way to find the extension
    // of an image file.
    //const fileExt = file.mimetype.split(&amp;quot;/&amp;quot;);

    // These
    const upload = {
      file: file,
      
      /* You may want to store this metadata in S3, but it&#39;s optional */
      filetype: file.mimetype,
      
      /* You may want to add this to the filename */
      //fileExt: fileExt[fileExt.length - 1],
      
      /* You may want to use the original filename */
      //filename: file.originalname,
      
      /* We&#39;re going to use a random UUID file name in this example.
         One thing that this does is makes sure it is unique.
         If you upload a file with the same name it will overwrite the
         existing file! */
      id: uuidv4()
    }
  
    // Upload the file, see ./helpers/aws.js
    const response = await aws.upload(upload);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the &lt;code&gt;aws.js&lt;/code&gt; module first there is some general configuration. This is where we will access our &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;, &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, and &lt;code&gt;S3BUCKET&lt;/code&gt; ENV variables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aws.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;// The AWS package is used for all AWS services,
// we only need the S3 part:
var AWS = require(&#39;aws-sdk&#39;);
var s3 = new AWS.S3({
  signatureVersion: &#39;v4&#39;
});

// Store your AWS creds in ENV variables:
AWS.config.update({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
});

// Your bucket isn&#39;t secret, but you may want to use
// different buckets for dev and production so it&#39;s
// helpful to store in an ENV variable.
var bucketName = process.env.S3BUCKET;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are also 2 functions: &lt;code&gt;upload()&lt;/code&gt;, which takes one &lt;code&gt;uploadObject()&lt;/code&gt; parameter, uploads a file to S3, and returns confirmation and the S3 object&#39;s key, and &lt;code&gt;getSignedUrl&lt;/code&gt;, which takes an S3 key, and returns the file (more on this later).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;upload()&lt;/code&gt; is what we passed our &lt;code&gt;file&lt;/code&gt; object from &lt;code&gt;server.js&lt;/code&gt; to. This function is essentially a wrapper around the &lt;code&gt;aws-sdk&lt;/code&gt;&#39;s &lt;code&gt;S3.putObject()&lt;/code&gt; method. We collect the necessary parameters in an object, then pass that object to the method which we&#39;ve defined as &lt;code&gt;s3.putObject()&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aws.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;    // AWS S3 Upload params:
    var params = {
      // S3 stores files in buckets, each bucket
      // has a globally unique name.
      Bucket: bucketName,

      // This will be the filename in AWS
      Key: uploadObject.id,

      // This is the contents of the file.
      Body: uploadObject.file.buffer,

      // This is optional, but your file in S3 won&#39;t have Content-Type
      // metadata unless you include it.
      ContentType: uploadObject.filetype
    };
  
  
    const responseData = await s3.putObject(params).promise();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is all wrapped in a &lt;code&gt;try&lt;/code&gt; / &lt;code&gt;catch&lt;/code&gt; block so if there aren&#39;t any errors we can pass the key back to &lt;code&gt;server.js&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aws.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;    // Likely this won&#39;t happen because an error will be thrown,
    // but it&#39;s good to check just in case. ¬Ø\_(„ÉÑ)_/¬Ø 
    if (!responseData) {
      throw &amp;quot;Upload failed&amp;quot;
    }
      
    // The response data has a single property, &amp;quot;ETag&amp;quot;,
    // you probably won&#39;t need to do anything with it.

    const s3Data = {
      success: true,

      // This key is what you would store in a DB, we didn&#39;t
      // get this back from S3, but since there wasn&#39;t an error
      // we trust that it is saved.
      key: params.Key

      // Or, the url below could be stored if the permissions on the bucket
      // or the upload are publically viewable.
      //url: &amp;quot;https://&amp;quot; + bucketName + &amp;quot;.s3.amazonaws.com/&amp;quot; + params.Key
    }

    // Send the object with success and the key back to server.js
    return(s3Data)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&#39;s important to note that the &lt;code&gt;id&lt;/code&gt; we pass back to &lt;code&gt;server.js&lt;/code&gt; isn&#39;t returned to us from the &lt;code&gt;s3.putObject()&lt;/code&gt; method. &lt;code&gt;s3()&lt;/code&gt; returns an &lt;code&gt;ETag&lt;/code&gt;, which isn&#39;t of much use for what we&#39;re doing, but it&#39;s enough to confirm that the upload completed successfully (What are ETags? &lt;a href=&quot;https://teppen.io/2018/06/23/aws_s3_etags/&quot;&gt;teppen.io/2018/06/23/aws_s3_etags/&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Going back to server.js, this is where we would want to store our &lt;code&gt;id&lt;/code&gt; somewhere. This string is what we will need to retrieve the file from s3. In this app we&#39;re just demoing the upload functionality so we don&#39;t store it anywhere. We access it once though to show the user that it worked. This is where we will use the other function in the &lt;code&gt;aws&lt;/code&gt; module, &lt;code&gt;getSignedUrl&lt;/code&gt;. Because our S3 bucket permissions only let our AWS user access objects, and otherwise our bucket permissions are &amp;quot;No public access&amp;quot;, we need to create a temporary signed URL to access the file.&lt;/p&gt;
&lt;p&gt;Using the id returned from the &lt;code&gt;upload()&lt;/code&gt; function we call the &lt;code&gt;getSignedUrl()&lt;/code&gt; function. When we get the signed url, we put it into some simple HTML to display it to the user (this is the main difference between the two &lt;code&gt;server.js&lt;/code&gt; routes):&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;    // Confirm upload succeeded:
    if (!response.success || response.error) {
      throw &amp;quot;Reponse Error: &amp;quot; + response.error;
    }
    
    /* - - - - -
      You might want to do something with the response.key or
      response.url here.
    - - - - - */
    
    
    // Because our bucket is not publically viewable we need to
    // get a signed URL to view the uploaded file. You DO NOT want
    // to store this signed URL in a DB, it will expire. You will
    // want to store either the key or url from the AWS response
    // above.
    
    // Get a new signed URL now that the file is uploaded:
    // Getting a signed URL requires the Bucket Name and the
    // file id, but we are using the same bucket name for everything
    // in this example. See ./helpers/aws.js for how this works.
    const url = await aws.getSignedUrl(upload.id);

    // Very simple HTML response containing the URL and it rendered
    // as an image (if the file is not an image this will look like
    // a broken image).
    res.status(200).send(`
      &amp;lt;p&amp;gt;
        &amp;lt;strong&amp;gt;Signed URL:&amp;lt;/strong&amp;gt; &amp;lt;a href=&amp;quot;${url}&amp;quot;&amp;gt;${url}&amp;lt;/a&amp;gt;
      &amp;lt;/p&amp;gt;
      &amp;lt;h4&amp;gt;If it&#39;s an image:&amp;lt;/h4&amp;gt;
      &amp;lt;img src=&amp;quot;${url}&amp;quot; width=&amp;quot;400&amp;quot; /&amp;gt;
    `); 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;getSignedUrl()&lt;/code&gt; function in &lt;code&gt;aws&lt;/code&gt; is a wrapper around the &lt;code&gt;S3.getSignedUrl&lt;/code&gt; method (mostly putting it in our &lt;code&gt;aws&lt;/code&gt; module allows us to avoid passing the Bucket Name from our routes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;aws.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;// This function will get a signed URL which allows
// access to non public objects, and objects in non
// public buckets for a limited time.
async function getSignedUrl(key) {
  
  // We are already authenticated so we just need the
  // bucket name and the object&#39;s key.
  var params = {
    Bucket: bucketName,
    Key: key
  };
  
  // The getSignedUrl method returns the url.
  const url = await s3.getSignedUrl(&#39;getObject&#39;, params);
  return url
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&#39;s it! Try out the app (in this example uploads are limited in size to 4KB for safety). You can &lt;a href=&quot;https://glitch.com/edit/#!/aws-s3-example&quot;&gt;remix the app on Glitch&lt;/a&gt; or &lt;a href=&quot;https://github.com/patrickweaver/aws-s3-example&quot;&gt;fork it on GitHub&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>How to Download an Image from a Google Doc</title>
    <link href="https://patrickweaver.net/blog/how-to-download-an-image-from-a-google-doc/"/>
    <updated>2020-07-16T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/how-to-download-an-image-from-a-google-doc/</id>
    <content type="html">&lt;p&gt;For some reason Google hasn&#39;t built in a way for you to download images in Google docs! There are workarounds to get those image files like &lt;a href=&quot;https://twitter.com/corduroy/status/1184758335934849025&quot;&gt;using Google Keep&lt;/a&gt;, or &lt;a href=&quot;https://twitter.com/tonyvincent/status/1021726699178708993&quot;&gt;downloading your whole doc as a .zip file&lt;/a&gt;, but these have always felt like too many steps.&lt;/p&gt;
&lt;p&gt;And this is something that people really want!&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1190182191520788480&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1277776054380265478&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/710516705303384068&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1227582581350240257&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1225516004375179265&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1249761603559378945&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/990395429383622656&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;As Steve Krouse points out here, it is possible to get the real URL of the image in your doc (but confusingly, as soon as you click on the image to select it the URL becomes obfuscated!).&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;a href=&quot;https://twitter.com/user/status/1190358282877186050&quot;&gt;&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;I also noticed the URLs in the source, and decided to make an easy way to access it. The one trick ended up being, because clicking on the image made it disappear, finding a way to tell the code which image you wanted!&lt;/p&gt;
&lt;p&gt;I looked through some JavaScript documentation and realized I could use the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Element/mouseover_event&quot;&gt;mouseover&lt;/a&gt; event to detect when someone was hovering over the image. Unfortunately this means that it won&#39;t work on a touchscreen device, but I&#39;m guessing that most people who want to download an image are on a traditional computer.&lt;/p&gt;
&lt;h2&gt;How does it work?&lt;/h2&gt;
&lt;p&gt;I needed a way to run my code on any Google Doc, there&#39;s probably a way to make Google Doc or Chrome extension to do this, but since I was asking people to run code in their potentially private docs I wanted to make the code as short and open source as possible.&lt;/p&gt;
&lt;p&gt;I decided that the best way to do this was a &lt;a href=&quot;https://support.mozilla.org/en-US/kb/bookmarklets-perform-common-web-page-tasks&quot;&gt;bookmarklet&lt;/a&gt;. If you&#39;re unfamiliar with bookmarklets, they&#39;re bookmarks (usually placed in your bookmarks toolbar (Cmd-Shift-B to toggle this on and off on a Mac), that instead of navigating to a webpage, run JavaScript when you click them.&lt;/p&gt;
&lt;h2&gt;Great! Tell me how to do it!&lt;/h2&gt;
&lt;p&gt;To get started you&#39;ll have to &amp;quot;install&amp;quot; the bookmarklet. This is easy to do, and just means dragging a button into your bookmarks toolbar. &lt;a href=&quot;https://gdoc-image-dl.glitch.me/&quot;&gt;I&#39;ve hosted it on Glitch here&lt;/a&gt;. You can even drag it straight from one of the buttons on the embed below:&lt;/p&gt;
&lt;div class=&quot;glitch-embed-wrap&quot; style=&quot;height: 420px; width: 100%;&quot;&gt;&lt;iframe allow=&quot;geolocation; microphone; camera; midi; encrypted-media&quot; src=&quot;https://glitch.com/embed/#!/embed/gdoc-image-dl?path=README.md&amp;previewSize=100&quot; alt=&quot;record-player on Glitch&quot; style=&quot;height: 100%; width: 100%; border: 0;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;The instructions are simple!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Drag one of the bookmarklets below  =(see the embed above) to your bookmarks toolbar. The text displayed is what will be show on the toolbar:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, when you&#39;re on a Google Doc, click the bookmarklet, then hover over an image embeded in the doc. Depending on your browser settings it will either download immediately, or open the actual image in a new tab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Great my problems are solved forever!&lt;/h2&gt;
&lt;p&gt;No guarantees that this will work long term, a quick look at the source code for any Google Doc will show that they&#39;re very complex! I wouldn&#39;t be surprised if Google changes the way these URLs work in the future, but this tool has worked for 6 months so maybe not!&lt;/p&gt;
&lt;p&gt;Long term I hope that they build in a way for people to download their images, but for now I hope this is helpful!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Week 1 at Recurse Center: Two Approaches to Learning</title>
    <link href="https://patrickweaver.net/blog/recurse-center-week-1/"/>
    <updated>2020-08-16T22:22:13Z</updated>
    <id>https://patrickweaver.net/blog/recurse-center-week-1/</id>
    <content type="html">&lt;p&gt;I just finished my first week as part of the Fall 1 &#39;20 batch at &lt;a href=&quot;https://www.recurse.com/&quot;&gt;Recurse Center&lt;/a&gt;. I tried to split my time between being social and building skills that I want to use for future projects. The social aspect of RC is interesting because this batch is being conducted remotely.&lt;/p&gt;
&lt;p&gt;My batch at RC started exactly 5 months after my last day in an office, and something I had been thinking about over the last few months, is that I haven&#39;t met anyone new since early March when NYC shut down because of the pandemic. It&#39;s been very refreshing to meet people again, even if it&#39;s via video calls and chat. RC has created an online representation of their physical space we call &amp;quot;Virtual RC&amp;quot;. Each of us have avatars we can move around the space, and there are permanent links to video call rooms that we can pop into for events or impromptu conversations. The Virtual RC experience pairs well with group chat organized into streams on different topics.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/rc/virtual-rc.png&quot; alt=&quot;A screenshot of Virtual RC&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;My avatar hanging out in the &quot;Shannon&quot; room at Virtual RC&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Other than social events I spent my first week at RC focused on two projects. The first was going through the &lt;a href=&quot;https://www.hackingwithswift.com/100/swiftui&quot;&gt;100 Days of SwiftUI tutorials&lt;/a&gt; (at many more than one a day), which I had started before the batch. The second was reviewing the &lt;a href=&quot;https://github.com/patrickweaver/nyc-subway&quot;&gt;real time NYC Subway map&lt;/a&gt; project I first started in January.&lt;/p&gt;
&lt;p&gt;I wish I had been able to finish the SwiftUI tutorials before the batch (my original goal), because it didn&#39;t feel as useful to share what I was working on with other RC participants as I was re-building apps that someone else had designed, but I finished the last app on Friday and I&#39;m excited to be able to use SwiftUI to quickly prototype projects for my phone.&lt;/p&gt;
&lt;p&gt;When I first started the subway map project in early 2020 I was excited about finishing it quickly, but in March when I also stopped taking the subway I lost enthusiasm for the project. Starting at RC has helped rekindle the excitement I had for it, I think partly because even though the batch is remote and there are participants from around the world, there is also a strong NYC contingent.&lt;/p&gt;
&lt;p&gt;An interesting aspect of building a map from MTA data is that the data structures that the MTA publishes are designed for building countdown clock style apps. I would imagine that the MTA calculates this per-station data from the location of each train, but in order to build an app that is more focused on location than time, I need to reverse engineer the location data from the distance in time each train from the next station. There are also other weird quirks, like train trip start times being provided in &amp;quot;HH:MM:SS&amp;quot; format, but station arrival times being provided in Unix time format.&lt;/p&gt;
&lt;figure&gt;
&lt;pre&gt;&lt;code&gt;{ &amp;quot;id&amp;quot;: &amp;quot;000001G&amp;quot;,
  &amp;quot;tripUpdate&amp;quot;: {
    &amp;quot;trip&amp;quot;: {
      &amp;quot;tripId&amp;quot;: &amp;quot;126481_G..N&amp;quot;,
      &amp;quot;startTime&amp;quot;: &amp;quot;21:04:49&amp;quot;,
      &amp;quot;startDate&amp;quot;: &amp;quot;20200815&amp;quot;,
      &amp;quot;routeId&amp;quot;: &amp;quot;G&amp;quot;
    },
    &amp;quot;stopTimeUpdate&amp;quot;: [
      { &amp;quot;arrival&amp;quot;: { &amp;quot;time&amp;quot;: &amp;quot;1597541836&amp;quot; },
        &amp;quot;departure&amp;quot;: { &amp;quot;time&amp;quot;: &amp;quot;1597541836&amp;quot; },
        &amp;quot;stopId&amp;quot;: &amp;quot;G28N&amp;quot; },
      { &amp;quot;arrival&amp;quot;: { &amp;quot;time&amp;quot;: &amp;quot;1597541904&amp;quot; },
        &amp;quot;departure&amp;quot;: { &amp;quot;time&amp;quot;: &amp;quot;1597541904&amp;quot; },
        &amp;quot;stopId&amp;quot;: &amp;quot;G26N&amp;quot; }
        
      /* More stations below in real data */
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;figcaption&gt;Example MTA Data&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Splitting my programming time between learning SwiftUI and trying to wrap my head around the subway map again has felt like two different approaches to learning. In the past I have often jumped into building my own projects with a new tool or technology as soon as I feel like I had learned enough to do so, but I&#39;ve often realized later that I spent a lot of time figuring out answers that I might have gotten to more quickly by completing a more thorough overview before starting.&lt;/p&gt;
&lt;p&gt;The subway map is one example of that type of project, but for good reason. It&#39;s a project that when I started, I wasn&#39;t sure was possible. It was inspired by a similar (but much simpler) map in the underground MUNI stations in San Francisco. The MUNI maps I remember from 15 years ago only showed trains in &amp;quot;the tunnel,&amp;quot; which although many lines run through, has a single trunk, that lines branch out from after going above ground (newer maps as seen below seem to show the whole system). Since these MUNI maps had existed since at least the early 00s I figured if one hadn&#39;t been made (I&#39;ve since found &lt;a href=&quot;https://tracker.geops.ch/?z=13&amp;amp;s=1&amp;amp;x=-8232001.0970&amp;amp;y=4969606.7622&amp;amp;l=transport&quot;&gt;NYC maps that have been made&lt;/a&gt;) for NY there must be a technical reason (it may just be that because until relatively recently &lt;a href=&quot;https://www.theatlantic.com/technology/archive/2015/11/why-dont-we-know-where-all-the-trains-are/415152/&quot;&gt;per station data wasn&#39;t available&lt;/a&gt; in NYC).&lt;/p&gt;
&lt;figure&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/MBTA?ref_src=twsrc%5Etfw&quot;&gt;@MBTA&lt;/a&gt; &lt;a href=&quot;https://twitter.com/sfmta_muni?ref_src=twsrc%5Etfw&quot;&gt;@sfmta_muni&lt;/a&gt; &lt;a href=&quot;https://twitter.com/d_tribe?ref_src=twsrc%5Etfw&quot;&gt;@d_tribe&lt;/a&gt; &lt;a href=&quot;https://twitter.com/universalhub?ref_src=twsrc%5Etfw&quot;&gt;@universalhub&lt;/a&gt; closer zoom. Incredibly useful. &lt;a href=&quot;https://t.co/jqHuGyZrJR&quot;&gt;pic.twitter.com/jqHuGyZrJR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Ari Ofsevit (@ofsevit) &lt;a href=&quot;https://twitter.com/ofsevit/status/720301082899918850?ref_src=twsrc%5Etfw&quot;&gt;April 13, 2016&lt;/a&gt;&lt;/blockquote&gt; &lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;figcaption&gt;
&lt;p&gt;A photo of the real time MUNI map in a tweet by &lt;a href=&quot;https://twitter.com/ofsevit/status/720301082899918850&quot;&gt;@ofsevit&lt;/a&gt;&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In order to gauge the feasibility of the project I wanted to get started quickly, throwing a map together and adding some markers for stations and individual trains at fixed times. Because I had limited experience working with transit data (which is provided in a &lt;a href=&quot;https://developers.google.com/transit/gtfs&quot;&gt;very complex format&lt;/a&gt;), or maps, this left me with both the sense that the project is possible, and a big spaghetti code mess.&lt;/p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/rc/nyc-subway-v1.png&quot; alt=&quot;A screenshot of the first prototype of my subway map app&quot; /&gt;&lt;/p&gt;
&lt;figcaption&gt;The first prototype of the subway map app&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I started looking into SwiftUI because I&#39;m interested in making my own home screen widgets once I update my phone to iOS 14, and these widgets are built using the framework. Knowing I would have time to experiment during my batch at RC, and wanting to avoid my usual new tool mess phenomenon, I prioritized giving myself a good understanding of how SwiftUI works, what it can and can&#39;t do, and a general review of Swift. Once my batch started I found it more and more difficult to keep going through the tutorials instead of jumping into an original idea, but throughout the week, spending time figuring out what I was even thinking reviewing the code for the subway map project re-motivated me to get through it.&lt;/p&gt;
&lt;p&gt;In the first week at RC the return to a daily routine has also put me back in the frame of mind I spent a lot of my last job in, where I would come up with ideas for about 3 apps a day that would solve tiny problems. One example is, after a particular session of an RC event for pair programming on software job interview style questions where we selected a problem that ended up being very difficult in the language we chose to work in, I thought that maybe I should create a mini app for the group where we could rate problems for each other. A lot of these ideas that are generated through trying to solve small problems in my routine end up being apps that organize data into text boxes, which are often not very interesting, so I&#39;m conflicted on whether or not to spend time following these threads that will likely continue to appear.&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;rc-goals&quot;&gt;A few other things that are slightly more interesting, or at least broadly useful that I want to get done during my time at RC are:&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The real time subway map&lt;/li&gt;
&lt;li&gt;A simple checklist app with a home screen widget made with SwiftUI&lt;/li&gt;
&lt;li&gt;A tool to convert an export from a Blogger blog to a static site generator&lt;/li&gt;
&lt;li&gt;A prototype of a self-hosted social network profile that can interface with other people&#39;s self-hosted profiles&lt;/li&gt;
&lt;li&gt;A second iteration of my &lt;a href=&quot;https://github.com/patrickweaver/ocr-email&quot;&gt;handwritten email sending project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Something that takes ideas similar to Dynamicland (or the &lt;a href=&quot;https://www.recurse.com/blog/132-living-room-making-rc-programmable&quot;&gt;Living Room&lt;/a&gt; project at RC) into the remote world we&#39;re living in.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall I&#39;m very excited to be spending time at RC, and I hope that it gives me time to explore ideas with weird corners and not settle for solving small simple problems quickly.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Making a Real-Time NYC Subway Map with Real Weird NYC Subway Data</title>
    <link href="https://patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/"/>
    <updated>2020-10-21T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/</id>
    <content type="html">&lt;p&gt;Earlier this week the NYC MTA released a new &lt;a href=&quot;https://map.mta.info/&quot;&gt;digital-first map&lt;/a&gt;. The &lt;a href=&quot;https://www.curbed.com/2020/10/first-look-new-yorks-digital-subway-map-comes-alive-today.html&quot;&gt;Curbed exclusive&lt;/a&gt; that announced its release accurately portrays it as a strange child of both the 1972 map design by Massimo Vignelli and the current &lt;a href=&quot;https://new.mta.info/map/5256&quot;&gt;‚Äúpaper‚Äù map&lt;/a&gt;. One feature of the new map (though it&#39;s harder than it should be to notice at first) is real-time visualizations of each train in the system.&lt;/p&gt;
&lt;p&gt;I&#39;ve been working on a similar concept, starting in February 2020, on which progress stalled once I stopped riding the subway regularly in March. But, when I started my batch at &lt;a href=&quot;https://www.recurse.com/&quot;&gt;Recurse Center&lt;/a&gt; I decided to pick up the project again. My inspiration for the map was the large TV screens that the MTA has installed in stations over the last few years, which frustratingly display the ‚Äúpaper‚Äù version of the map.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/nyc-subway/tv-screen-map.jpg&quot; alt=&quot;A photograph of a TV in a subway station with the ‚Äúpaper‚Äù map displayed.&quot; style=&quot;max-height: 400px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;Subway station TV (This is not a good photo, but it‚Äôs hard to take a picture of a screen underground)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Over the past few weeks at RC the subway map has been my main focus, which is longer than I expected the project to take (and though I have a prototype, I wouldn‚Äôt say I‚Äôm close to ‚Äúdone‚Äù). A big factor in the time the project has taken is some of the quirks in working with MTA data, which based on some of the bugs I&#39;ve seen in the &amp;quot;official&amp;quot; version I&#39;d say the team working on that version had to grapple with as well.  I&#39;m not sure I will ever finish this project to a state that would look great on a subway station tv, or be useful, but I do want to point out &lt;a href=&quot;https://www.theweekendest.com/trains&quot;&gt;The Weekendest&lt;/a&gt; by &lt;a href=&quot;https://sunny.ng/&quot;&gt;Sunny Ng&lt;/a&gt; (who also made &lt;a href=&quot;https://www.goodservice.io/&quot;&gt;goodservice.io&lt;/a&gt;), which is a great take on the concept, and handles some of the challenges of this kind of project much better than the MTA map does.&lt;/p&gt;
&lt;p&gt;For a long time the NYC Subway was almost &lt;a href=&quot;https://www.theatlantic.com/technology/archive/2015/11/why-dont-we-know-where-all-the-trains-are/415152/&quot;&gt;completely lacking in real-time data&lt;/a&gt;. For many years the only line that had even countdown clocks in stations was the L, which seems to be the line the MTA tries out new technology on, likely because it never shares tracks with any other line. Over the last 5 years the MTA has slowly installed countdown clocks in every station, and made the data that powers the countdown clocks available on their website, in apps, and as data online.&lt;/p&gt;
&lt;p&gt;Inspired and frustrated by the ‚Äúpaper‚Äù maps on the tv screens, I first became interested in working with MTA data in 2018, but I initially started working with bus data, I think for two reasons: the first was because at the time the API key for working with bus data was easier to obtain than for subway data, the second because my morning commute at the time usually started with the bus (The MTA, earlier this year, has fortunately updated the system for obtaining an API key for subway data). I made a small prototype of an iPhone app that would show real-time bus data, but got distracted by learning the Swift programming language and abandoned the project without building functionality beyond what the MTA already provided &lt;a href=&quot;https://bustime.mta.info/&quot;&gt;on their bustime website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That MTA Bustime website was the other inspiration for what became my map idea. Though you could only view one route at a time (and the functionality is not available on phone-size devices), the Bustime website showed, in addition to countdowns for each stop, the physical location of each bus on a map. This leads us to the first weird thing about working with NYC Subway data, unlike real-time bus data, the subway data does not contain the latitude and longitude data for each train that would make it easy to show them on a map.&lt;/p&gt;
&lt;h3&gt;Real-Time Transit Data&lt;/h3&gt;
&lt;p&gt;Transit data for most transit systems is available in formats called &lt;a href=&quot;https://developers.google.com/transit/gtfs&quot;&gt;GTFS&lt;/a&gt; (General Transit Feed Specification) and &lt;a href=&quot;https://developers.google.com/transit/gtfs-realtime&quot;&gt;GTFS Realtime&lt;/a&gt;, which were developed by Google (makes you wonder what the ‚ÄúG‚Äù originally stood for), but are now widely used. A GTFS file is, ‚Äúa collection of at least six, and up to 13 CSV files (with extension .txt) contained within a .zip file.‚Äù and ‚ÄúThe GTFS Realtime data exchange format is based on Protocol Buffers‚Äù (which are &lt;a href=&quot;https://developers.google.com/protocol-buffers&quot;&gt;‚ÄúGoogle&#39;s language-neutral, platform-neutral, extensible mechanism for serializing structured data‚Äù&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The GTFS Realtime feeds are available through 9 different API endpoints from the MTA. These 9 endpoints roughly correspond to the line colors, with Shuttles combined with trains they share tracks or stations with, and the 1/2/3 and 4/5/6 sharing one endpoint. This list of separate endpoints is another challenge with working with the entirety of the MTA data.&lt;/p&gt;
&lt;p&gt;I have exclusively worked with the NYC MTA‚Äôs GTFS Realtime feeds through the &lt;a href=&quot;https://www.npmjs.com/package/gtfs-realtime-bindings&quot;&gt;npm module&lt;/a&gt; maintained by Google. It is very possible that some of the challenges I‚Äôve encountered are due to trying to squeeze the ‚Äúextensible mechanism for serializing structured data‚Äù into JSON. Each API response is mostly composed of an array of &amp;quot;Feed Entity&amp;quot; objects like &lt;a href=&quot;https://patrickweaver.net/notes/nyc-subway-feed-entity/&quot;&gt;these&lt;/a&gt;, but there are a few quirks to working with this data (some maybe because of the JSON conversion).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each item in the array has an &lt;code&gt;id&lt;/code&gt; property, but unfortunately these ids do not consistently refer to the same train between each update, it&#39;s best to ignore it.&lt;/li&gt;
&lt;li&gt;The array consists of pairs of objects that either have a &lt;code&gt;tripUpdate&lt;/code&gt; property or a &lt;code&gt;vehicle&lt;/code&gt; property. Each of these have a sub-property called &lt;code&gt;tripId&lt;/code&gt; that allows you to unite the pairs, but there are also some that don&#39;t have a corresponding item (usually these represent trips that recently ended or haven&#39;t yet begun).&lt;/li&gt;
&lt;li&gt;The data mixes together HH:MM:SS timestamps for data about when a train&#39;s trip started, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Unix_time&quot;&gt;Unix timestamps&lt;/a&gt; for data about the current time (according to the API) and when a train will arrive at a station (the API provides both arrival and departure times but as far as I have seen they are always identical).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tripUpdate&lt;/code&gt; items show information about the stops a train will make in the future (stopTimeUpdates) and vehicle items show information about the current status of the train, but the first &lt;code&gt;stopTimeUpdate&lt;/code&gt; is usually in the past.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I had never heard of Protocol Buffers before starting this project, so I was excited to learn more about them while reading through &lt;a href=&quot;https://dataintensive.net/&quot;&gt;Designing Data Intensive Applications&lt;/a&gt; with fellow Recursers.  In the book Martin Kleppmann notes that a, &amp;quot;curious detail of Protocol Buffers is that it does not have a list or array datatype, but instead has a repeated marker for fields (which is a third option alongside required and optional).&amp;quot; This could be the reason for the strange organization of the &lt;code&gt;tripUpdate&lt;/code&gt; and &lt;code&gt;vehicle&lt;/code&gt; properties.&lt;/p&gt;
&lt;h3&gt;Calculating Train Locations&lt;/h3&gt;
&lt;p&gt;The subway real-time API doesn‚Äôt have latitude and longitude data because it is designed to feed data to countdown clock style applications that show when the train will be at a specific station. One of the earliest features that I built into the real-time map was a way to translate these station-by-station countdown clocks into an approximation of the location of each train. My first attempt at this was to just show a list of stations and display an icon for a train between the names of the station it had been at previously and the station it was approaching.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/nyc-subway/prototype-diagram.png&quot; alt=&quot;An early prototype diagram of G train positions.&quot; style=&quot;max-height: 400px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;A first prototype, still available at: &lt;a href=&quot;https://nyc-subway-g.glitch.me/&quot;&gt;nyc-subway-g.glitch.me&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The next step was plotting the stations on a map. To start off, as with the diagram version, I just placed each train at the midpoint between the station it was travelling from and the station it was travelling towards.&lt;/p&gt;
&lt;p&gt;A goal I had for the project was not just to show real-time train locations, but to animate them as they moved around the map. To determine how long I should expect a train to take to travel between each station I logged updates from the MTA API for a few hours and noted both the average time for a pair of stations, and the longest time I had seen for the pair. I&#39;m still experimenting a little bit with what values to use as the baseline, but from looking at the logged numbers there does seem to be an expected amount of time for most stations.&lt;/p&gt;
&lt;figure&gt;
&lt;div class=&quot;data&quot;&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;G: {
   G22: { N: { avg: 60, max: 71 }, S: null },
   G24: { N: { avg: 123, max: 180 }, S: { avg: 60, max: 106 } },
   G26: { N: { avg: 75, max: 90 }, S: { avg: 108, max: 180 } },
   G28: { N: { avg: 128, max: 180 }, S: { avg: 78, max: 90 } },
   G29: { N: { avg: 60, max: 76 }, S: { avg: 139, max: 180 } },
   G30: { N: { avg: 51, max: 74 }, S: { avg: 70, max: 90 } },
   G31: { N: { avg: 60, max: 90 }, S: { avg: 58, max: 69 } },
   G32: { N: { avg: 66, max: 87 }, S: { avg: 53, max: 84 } },
   G33: { N: { avg: 50, max: 66 }, S: { avg: 67, max: 84 } },
   G34: { N: { avg: 58, max: 90 }, S: { avg: 54, max: 66 } },
   G35: { N: { avg: 68, max: 86 }, S: { avg: 50, max: 81 } },
   G36: { N: { avg: 81, max: 161 }, S: { avg: 59, max: 71 } },
   A42: { N: { avg: 70, max: 177 }, S: { avg: 87, max: 157 } },
   F20: { N: { avg: 68, max: 90 }, S: { avg: 86, max: 165 } },
   F21: { N: { avg: 72, max: 120 }, S: { avg: 76, max: 120 } },
   F22: { N: { avg: 62, max: 90 }, S: { avg: 84, max: 120 } },
   F23: { N: { avg: 90, max: 120 }, S: { avg: 88, max: 150 } },
   F24: { N: { avg: 101, max: 120 }, S: { avg: 67, max: 84 } },
   F25: { N: { avg: 139, max: 180 }, S: { avg: 71, max: 90 } },
   F26: { N: { avg: 120, max: 120 }, S: { avg: 109, max: 150 } },
   F27: { N: null, S: { avg: 81, max: 120 } },
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;figcaption&gt;Average and max wait times in seconds for stops on the G line.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Trip Id&lt;/th&gt;
&lt;th&gt;Trip Start Time&lt;/th&gt;
&lt;th&gt;Trip Date&lt;/th&gt;
&lt;th&gt;Route&lt;/th&gt;
&lt;th&gt;Stop1 Arrival&lt;/th&gt;
&lt;th&gt;Stop1 Id&lt;/th&gt;
&lt;th&gt;Stop2 Arrival&lt;/th&gt;
&lt;th&gt;Stop2 Id&lt;/th&gt;
&lt;th&gt;Seconds&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;073476_G..N&lt;/td&gt;
&lt;td&gt;12:14:46&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597768631&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597768692&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;074600_G..N&lt;/td&gt;
&lt;td&gt;12:26:00&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597769103&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597769172&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;69&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;075000_G..N&lt;/td&gt;
&lt;td&gt;12:30:00&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597769531&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597769596&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;076501_G..N&lt;/td&gt;
&lt;td&gt;12:45:01&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597770333&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597770396&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;077700_G..N&lt;/td&gt;
&lt;td&gt;12:57:00&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597771043&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597771104&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;078403_G..N&lt;/td&gt;
&lt;td&gt;13:04:02&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597771443&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597771524&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;079600_G..N&lt;/td&gt;
&lt;td&gt;13:16:00&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597772051&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597772112&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;61&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;080550_G..N&lt;/td&gt;
&lt;td&gt;13:25:30&lt;/td&gt;
&lt;td&gt;20200818&lt;/td&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;1597772711&lt;/td&gt;
&lt;td&gt;G33N&lt;/td&gt;
&lt;td&gt;1597772776&lt;/td&gt;
&lt;td&gt;G32N&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;Logged travel Times between the Bedford - Nostrand stop and the Myrtle - Willoughby stop on the G train&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3&gt;Secret Stations&lt;/h3&gt;
&lt;p&gt;One thing I discovered while logging updates from the MTA API was that it contained secret stations! The MTA provides a &lt;a href=&quot;http://web.mta.info/developers/data/nyct/subway/Stations.csv&quot;&gt;list of all of the stations in the system&lt;/a&gt; with data like latitude and longitude. Each station has an ID (see Stop1 and Stop2 id in the diagram above and called &amp;quot;GTFS Stop ID&amp;quot; in the list). The stop IDs are a letter and 2 numbers, with the letter often corresponding to the line it serves (or used to historically), and the numbers mostly occurring in sequence. but some trains would have planned &amp;quot;stops&amp;quot; at stations that weren&#39;t in the list! My best guess is that these stations are something station-like in the MTA&#39;s infrastructure, which usually appear near the end of a line.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;quot;H17&amp;quot; is between Howard Beach/JFK Airport and Broad Channel on the A and Rockaway Shuttle and is likely where the Shuttle trains go to turn around.&lt;/li&gt;
&lt;li&gt;&amp;quot;H19&amp;quot; is before the Broad Channel stop on the A and Rockaway Shuttle and may also be related to Shuttle turnaround?&lt;/li&gt;
&lt;li&gt;&amp;quot;H18&amp;quot; and &amp;quot;H05&amp;quot; are between Broad Channel and Beach 67 St on the A and Rockaway Shuttle, which may have to do with tracks that run between Beach 67 and Beach 90 Sts.&lt;/li&gt;
&lt;li&gt;&amp;quot;A29&amp;quot; is between Penn Station and 14th St on the A, C, and E, which is strange because the C and E stop at 23rd St., which is also between those stations, but has the ID &amp;quot;A30&amp;quot;.&lt;/li&gt;
&lt;li&gt;&amp;quot;A39&amp;quot; is between Fulton St. and High St. on the A and C, which might have something to do with the track stubs on the Brooklyn side (one of which is the NYC Transit museum).&lt;/li&gt;
&lt;li&gt;&amp;quot;A58&amp;quot; is between Grant Av. and 80th St. on the A, which, is where the A train emerges from a tunnel to run on elevated tracks.&lt;/li&gt;
&lt;li&gt;&amp;quot;A62&amp;quot; is between Rockaway Blvd. and 104th St. on the A and probably has something to do with the merging between the 3 versions of the A at Rockaway Blvd.&lt;/li&gt;
&lt;li&gt;&amp;quot;R60&amp;quot; is between Queensboro Plaza and Lexington Ave/59th St. on the N, R, and W. My guess is that this has something to do with the N/W and R tracks merging before going into a tunnel.&lt;/li&gt;
&lt;li&gt;&amp;quot;R65&amp;quot; is between the Whitehall St. and Court St. stops on the R, and could also be related to the same track stubs as &amp;quot;A39&amp;quot;.&lt;/li&gt;
&lt;li&gt;&amp;quot;B24&amp;quot; is between Bay 50th St and Coney Island on the D, and is probably the MTA Coney Island Yard.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Drawing the Static Map&lt;/h3&gt;
&lt;p&gt;I wasn&#39;t quite satisfied with the angular paths that drawing lines directly between stations created, and I was fortunately able to find &lt;a href=&quot;https://github.com/blahblahblah-/theweekendest&quot;&gt;Sunny Ng&#39;s advice&lt;/a&gt; on extracting shape arrays from the non real-time GTFS MTA data. Using these shape arrays I could draw route maps with smooth curves, and even animate trains along those curves. But one of the things that makes a subway map a subway map is seeing lines that run on the same tracks as parallel lines. I also wanted to double these lines and show Northbound and Southbound trains on separate tracks (something that the new MTA map fails to do).&lt;/p&gt;
&lt;p&gt;After trying to approach the parallel lines problem geometrically I was pointed in the right direction by a fellow RC participant and was able to draw great looking lines by treating the Latitude/Longitude points in the shape arrays as vectors (More on this in my &lt;a href=&quot;https://doodles.patrickweaver.net/drawing-parallel-lines-on-a-map/&quot;&gt;interactive slides on this problem&lt;/a&gt; and more on the &lt;a href=&quot;https://medium.com/transit-app/how-we-built-the-worlds-prettiest-auto-generated-transit-maps-12d0c6fa502f&quot;&gt;challenge of drawing nice train lines from the Transit app&lt;/a&gt;).&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;display: flex; max-width: 100%;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/nyc-subway/nyc-subway-f-g.png&quot; alt=&quot;A screenshot of my map.&quot; style=&quot;max-height: 500px; max-width: 49%; margin: 0 auto;&quot; /&gt;
  &lt;span style=&quot;width: 5px;&quot;&gt;&lt;/span&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/nyc-subway/mta-f-g.png&quot; alt=&quot;A screenshot of the MTA map.&quot; style=&quot;max-height: 500px; max-width: 49%; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;Similar sections of my map and the MTA map&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3&gt;A Prototype&lt;/h3&gt;
&lt;p&gt;My map is online at &lt;a href=&quot;https://nyc-subway.glitch.me/&quot;&gt;nyc-subway.glitch.me&lt;/a&gt;, bugs and all. I did most of the work on the map using only the G train API endpoint. This was a helpful limitation when I was first experimenting with what was possible using the data, but may have led to more bugs because of the slight differences in the data available for each set of lines.&lt;/p&gt;
&lt;p&gt;A common complaint about the new official real-time map is that it seems to use as much computer power as it can. My map isn&#39;t much better because it is doing all of the geographic calculations in the user&#39;s browser, my guess is that the MTA&#39;s map is also. One update I might take on over the next week and a half as my time at RC winds down is moving these calculations to a server, and sending only train position changes to the map visualization. This may also help with the bug my current prototype exhibits where leaving and coming back to the tab a few minutes later will cause trains to fly around the map without regard for the lines or stations.&lt;/p&gt;
&lt;p&gt;The MTA data is weird because it&#39;s created by a system that could never have anticipated the kind of systems that now try to contain it. Overall, working with and working around the weirdness in the data has been challenging, but a great reminder that the most interesting real-world problems are often hard to jam into our brittle computer systems, and that&#39;s probably a good thing.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Participating in a Remote Batch at the Recurse Center</title>
    <link href="https://patrickweaver.net/blog/a-recurse-center-remote-batch/"/>
    <updated>2021-01-25T16:33:26Z</updated>
    <id>https://patrickweaver.net/blog/a-recurse-center-remote-batch/</id>
    <content type="html">&lt;p&gt;Participating in a batch at the &lt;a href=&quot;https://www.recurse.com/&quot;&gt;Recurse Center&lt;/a&gt; is something that I‚Äôve thought on-and-off about doing since I found out about it (then called Hacker School) sometime between 2013 and 2015, but it just never seemed like the right time to leave my job and its subsidized health insurance until I was laid off (what turned out to be) early on in the pandemic. I had as recently as January 2020 been thinking, ‚Äúmaybe now is the right time to finally quit and do it,‚Äù and though I‚Äôm relieved I was able to get a few more months of savings and health insurance into 2020, participating in RC was the perfect change of pace and a motivating bridge between employment and the job search.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/rc-website.png&quot; alt=&quot;A screenshot from the Recurse Center website with a notice about operating remotely&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;Screenshot from recurse.com&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I had been working from home at my old job from mid March to when I left in mid July, but I didn‚Äôt realize until my first day at RC, that even though I had frequently seen friends and coworkers on video calls and in outdoor settings for the past 6 months, it was rare that I had the chance to speak to anyone I hadn‚Äôt previously met since March 2020.&lt;/p&gt;
&lt;p&gt;There are a few different pieces to the experience of a remote batch at RC. &lt;a href=&quot;https://www.recurse.com/virtual-rc&quot;&gt;Virtual RC&lt;/a&gt; is a fun game-like experience where each participant (and visiting alumni) has an avatar on the map. One corner of the map is more organized, and designed with a layout intended to mimic the physical RC space in Brooklyn, but the rest of the map is open for creative world building or experiments (there is even a Virual RC API now!). Each of the ‚Äúrooms‚Äù in the structured corner of the map has a persistant video call link in it, and you can see which other participants are in the room on a call. Since I‚Äôve started my new job I‚Äôve missed being able to see who is already in a zoom call before deciding to join an optional meeting! Participants are encouaged to create a desk, where you can set an emoji status and leave a short note describing what you are up to that day. There are also audio rooms, which are great for more informal, or group conversations, and I‚Äôm only realizing now how much easier it is to start a call when you don‚Äôt have to open a new link and wait for a video call service to connect. A lot of the day-to-day conversation at remote RC happens via text on &lt;a href=&quot;https://zulip.com/&quot;&gt;Zulip&lt;/a&gt; (though this was the case for in-person RC also). It‚Äôs easy to reach out for help or to look for a pairing buddy on Zuip, and one of the most active streams (like channels in other chat apps) is Checkins where in-batch Recursers regularly post about what they‚Äôre working on.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/virtual-rc.png&quot; alt=&quot;A screenshot from Virtual RC with my avatar on top of the RC logo drawn with wall blocks&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;Hanging out on top of the RC logo in Virutal RC&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I came into RC with &lt;a href=&quot;https://patrickweaver.net/blog/recurse-center-week-1/#rc-goals&quot;&gt;a few goals&lt;/a&gt; ranging form ambitious (real-time NYC subway map or self-hosted social network prototype), to the kinds of things I often made when I had a few hours to spare (SwiftUI proof of concept checklist app). I had spent the weeks leading up to my batch doing what I wanted to think of as a mini RC-like experience re-learning Swift and using SwiftUI for the first time. I had hoped to finish the &lt;a href=&quot;https://www.hackingwithswift.com/100/swiftui&quot;&gt;100 Days of SwiftUI&lt;/a&gt; tutorials in time for day 1 at RC but ended up being about a week too slow.&lt;/p&gt;
&lt;p&gt;I was surprised at the 9-5ness of the events and chatter in remote RC, though one of the most exciting things about doing a remote batch was being able to meet and collaborate with people from around the world (I counted at least 8 timezones in my batch), most events occurred bewteen 9am and 5pm Eastern Time. I would guess that this means that the average RC participant is spending less time in RC, than when in an in-person batch, which depending on your goals and ability to focus when something potentially more fun is going on, could be a benefit or a drawback to the remote RC experience.&lt;/p&gt;
&lt;p&gt;After speeding through the SwiftUI tutorials in my first week (and getting kind of tired of working in an unfamiliar language), I decided to spend most of my time working on my &lt;a href=&quot;https://patrickweaver.net/blog/making-a-real-time-nyc-subway-map-with-real-weird-nyc-subway-data/&quot;&gt;real-time NYC subway map project&lt;/a&gt; that I had first prototyped in early 2020. I eventually was able to get a mostly working prototype of the full system, coincidentally on almost the exact day that the MTA &lt;a href=&quot;https://www.curbed.com/2020/10/first-look-new-yorks-digital-subway-map-comes-alive-today.html&quot;&gt;released&lt;/a&gt; their own version. I thought that the subway map would be one of a few medium sized projects that I would be able to spend 2 to 3 weeks on during my RC time, but I had already spent more than half of my 12 week batch on it. I had done a few other one-off projects like an &lt;a href=&quot;https://10-print-video-game.glitch.me/&quot;&gt;abstract ‚Äúvideo game‚Äù&lt;/a&gt; based on the 10 Print pattern and a few explorations into techincal topics like &lt;a href=&quot;https://doodles.patrickweaver.net/canvas-lines/&quot;&gt;the browser JavaScript canvas API&lt;/a&gt;, but I decided that I should try to find a real medium-sized project for my last few weeks at RC.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/canvas-lines.png&quot; alt=&quot;A screenshot from my slides on drawing pixel perfect lines on the JS canvas&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;It&#39;s hard to draw crisp lines on the JS canvas!&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I felt like I had mostly been working though a big challenge with technologies that were pretty familiar so far (JavaScript and the &lt;a href=&quot;https://leafletjs.com/&quot;&gt;Leaflet.js mapping library&lt;/a&gt;), so I wanted to find a project that I could use to learn something new, but not spend all my time on implementation details like I had been doing learning SwiftUI. I had created a static website on the &lt;a href=&quot;https://doodles.patrickweaver.net/&quot;&gt;doodles subdomain&lt;/a&gt; of my website that I wanted to keep filling out, so a useful constraint was to make something on the web that wouldn‚Äôt need a backend (the doodles website is static and built with &lt;a href=&quot;https://www.11ty.dev/&quot;&gt;Eleventy&lt;/a&gt; , as are this website, and most of the doodles)). In the last year at my job, and through collaborating with other RC participants during my batch I had gotten pretty quick with prototyping things with React, but I hadn‚Äôt used either &lt;a href=&quot;https://reactjs.org/docs/hooks-intro.html&quot;&gt;React Hooks&lt;/a&gt;, or &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt; for anything. I decided to try learning both and created a &lt;a href=&quot;https://doodles.patrickweaver.net/crossword/editor&quot;&gt;web-based Crossword Puzzle composer&lt;/a&gt;.&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/crossword.png&quot; alt=&quot;A screenshot of the crossword puzzle app with symmetrical squares blacked out&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;A crossword puzzle with multiple kids of symmetries&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The crossword puzzle app was a fun mix of small challenges and interesting design decisions. One of the first things that stood out to me was that I had never really thought about the algorithm that is used to number crossword puzzle answers on the board, the kind of thing that is immediately understandable, but more complex that you would expect it to be when represented with a programming language. React Hooks were immediately very useful since most of the components for the app needed a sprinkling of state, but not too much, and TypeScript was helpful, especially in the context of RC because I paired with a few people on certain self-contained parts of the app like the symmetry for square toggling, and the defined types help people quickly pick up what the code we were writing would do. My favorite part of the crossword puzzle app is that to store a composed puzzle without a backend, I encode the whole puzzle state into the URL (here is a &lt;a href=&quot;https://doodles.patrickweaver.net/crossword/play/#eyJzdGF0ZSI6W1tbWyJmIiwiIiwiZmYiLG51bGwsbnVsbCwwXSxbImYiLCIiLCJ-mZiIsbnVsbCxudWxsLDFdLFsidCIsIlIiLCJ0dCIsMSwxLDJdLFsidCIsIkMiLC-JmdCIsMSwyLDNdXSxbWyJ0IiwiRiIsInR0IiwzLDMsNF0sWyJ0IiwiSSIsImZ0I-iwzLDQsNV0sWyJ0IiwiRiIsImZmIiwzLDEsNl0sWyJ0IiwiTyIsImZmIiwzLDIs-N11dLFtbInQiLCJBIiwidGYiLDUsMyw4XSxbInQiLCJNIiwiZmYiLDUsNCw5XSx-bInQiLCJJIiwiZmYiLDUsMSwxMF0sWyJ0IiwiRCIsImZmIiw1LDIsMTFdXSxbWy-J0IiwiTiIsInRmIiw2LDMsMTJdLFsidCIsIk8iLCJmZiIsNiw0LDEzXSxbInQiL-CJEIiwiZmYiLDYsMSwxNF0sWyJ0IiwiRSIsImZmIiw2LDIsMTVdXV0sW1tbImEi-LDEsIkZLQSBIYWNrZXIgU2NoLiIsIlJDIiwyXSxbImEiLDMsIk9yZGVyIGluIGE-gcXVldWUiLCJGSUZPIiw0XSxbImEiLDUsIkluIHRoZSBtaWRkbGUgb2YiLCJBTU-lEIiw4XSxbImEiLDYsIkphdmFTY3JpcHQgcnVudGltZSIsIk5PREUiLDEyXV0sW-1siZCIsMSwiV2lyZWxlc3MgdGVjaCB3aXRoIHRhZ3MiLCJSRklEIiwyXSxbImQi-LDIsIldoYXQgYSBwcm9ncmFtbWVyIHdyaXRlcyIsIkNPREUiLDNdLFsiZCIsMyw-iQ29tcHV0ZXIgYWlyIG1vdmVyIiwiRkFOIiw0XSxbImQiLDQsIlNob3J0aGFuZC-Bmb3Igb25lJ3MgcHJlZmVyZW5jZSIsIklNTyIsNV1dXV19&quot;&gt;small RC themed puzzle&lt;/a&gt;). I even discovered seemingly documented nowhere else bug in iMessage when prototyping this feature. When I first sent a friend a link to a puzzle as a test, iMessage wouldn‚Äôt parse it as a link, so they just got a wall of what looked like random characters. I looked around at other long tracking links I‚Äôd received in my emails and noticed they frequently had hyphen characters every so often. I added hyphens to my urls and all of a sudden iMessage could parse them as links!&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/imessage.png&quot; alt=&quot;A screenshot of a message in iMessage with a long stiring of seemingly random characters&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;A failed attempt to send a crossword&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;During the second half of my RC batch I also interviewed with a lot of companies. To help with this I attended a daily group for pairing on software job interview style questions. Coming back to these types of problems a few times a week was really helpful in being able to think through them quickly and I noticed a lot of progress in my ability to complete these kinds of challenges the more I practiced and interviewed.&lt;/p&gt;
&lt;p&gt;When I first applied to RC I had been feeling nervous about committing such a long period of time to not working before (hopefully!) starting a new job, I considered just doing a 1 week mini batch, or a 6 week half-batch, but the 12 weeks went by way more quikly than I had anticipated, and I was fortunately able to hit my idealistic goal of starting a new job in the new calendar year! The 12 weeks helped me feel free to dive into weird corners of the problems I wanted to work on like &lt;a href=&quot;https://doodles.patrickweaver.net/drawing-parallel-lines-on-a-map/&quot;&gt;drawing parallel lines on a map&lt;/a&gt; (lines were a big theme in my projects), without worrying that it would keep me from ‚Äúfinishing‚Äù my projects (author‚Äôs note: I still didn‚Äôt ‚Äúfinish‚Äù most of them). In the spirit of ‚Äúnever graduate‚Äù I hope to someday participate in another batch at the physical RC space, but in the meantime, anyone who like me has been sitting on the fence on applying to RC for years should take the opportunity to participate remotely and start the programming project you‚Äôve always been meaning to get to!&lt;/p&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;https://patrickweaver.net/images/blog/rc2/parallel-lines-curve.png&quot; alt=&quot;A screenshot of a prototype of my real-time subway map&quot; style=&quot;max-width: 500px; margin: 0 auto;&quot; /&gt;
&lt;/div&gt;
&lt;figcaption&gt;An early attempt to draw MTA track geography data as parallel tracks on a map&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
  </entry>
  
  <entry>
    <title>How to Set Up a Raspberry Pi as a Home Webserver</title>
    <link href="https://patrickweaver.net/blog/how-to-raspberry-pi-server/"/>
    <updated>2021-05-03T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/how-to-raspberry-pi-server/</id>
    <content type="html">&lt;p&gt;Like most of the world, I‚Äôve been spending a lot of time at home lately. Over the winter I was experimenting with building my own web-based digital tools, like an app to track articles and books I was reading. I initially thought I would need to buy hosting space to have the app accessible, but realized I mostly needed to use it when I was at home anyway, so a URL that only existed on my local network work also work.&lt;/p&gt;
&lt;p&gt;I have done a few projects with Raspberry Pis before, most notably a &lt;a href=&quot;https://www.patrickweaver.net/blog/building-a-futuristic-record-player-with-glitch-and-raspberry-pi/&quot;&gt;computer vision ‚Äúrecord player‚Äù&lt;/a&gt;, but always found myself looking up the same things like how to set up Wi-Fi and SSH access. I seemed to need to do the same handful of things every time, but they were spread across various documentation and how-tos. This time while setting up the Pi webserver I took notes so I would have it all in one place.&lt;/p&gt;
&lt;p&gt;To follow along with these steps you will need a second computer to set up the SD card (though you could probably start with a &lt;a href=&quot;https://www.adafruit.com/product/4266&quot;&gt;preformatted SD card also&lt;/a&gt;), and any kind of Raspberry Pi. I have run webservers on Pi Zeros before, though it can be a challenge to install newer versions of Node.js on ARMv6 based Pis (Zero and the original Raspberry Pi), and sometimes when building a large client app I‚Äôve had to move to a faster Pi from a Pi Zero.&lt;/p&gt;
&lt;h2&gt;SD Card Setup&lt;/h2&gt;
&lt;h3&gt;1. Install the OS&lt;/h3&gt;
&lt;p&gt;Raspberry Pi recently released their own tool for formatting SD cards, &lt;a href=&quot;https://www.raspberrypi.org/software/&quot;&gt;Raspberry Pi Imager&lt;/a&gt;. It makes the process a lot easier than it had been previously. The first step is picking an OS to format the card with. Any of the Debian-based OSes should work, though the smallest download is Raspberry Pi OS Lite, which is all you need if you won‚Äôt be connecting a display. After that, selec the SD card you want to install onto (there will probably only be one choice), and click ‚ÄúWrite‚Äù.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;1. Install the OS:&lt;/strong&gt; Use Raspberry Pi Imager tool to write the OS to the SD card &lt;a href=&quot;https://www.raspberrypi.org/software/&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/how-to-raspberry-pi-server/raspberry-pi-imager.png&quot; alt=&quot;A screenshot of the Raspberry Pi Imager Tool&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;2. Set up Wi-Fi&lt;/h3&gt;
&lt;p&gt;The RPi Imager tool will likely eject the SD card for you when it‚Äôs finished writing, but you want to do two more things before booting up the Pi. You may need to remove the SD card and re-insert it into your computer to see the ‚ÄúBoot‚Äù filesystem. First, to enable Wi-Fi you will need to create a file with your network credentials. If you will be plugging the Pi into an eithernet cord you can skip this step.&lt;/p&gt;
&lt;p&gt;Create a file called &lt;code&gt;wpa_supplicant.conf&lt;/code&gt; in the root directory of the SD card. Open the file in a text editor and paste in the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-conf&quot;&gt;ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
update_config=1
country=&amp;lt;2 LETTER ISO 3166-1 COUNTRY CODE&amp;gt;

network={
    ssid=&amp;quot;&amp;lt;WI-FI SSID&amp;gt;&amp;quot;
    psk=&amp;quot;&amp;lt;WI-FI PASSWORD&amp;gt;&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Update the &lt;code&gt;country&lt;/code&gt; line with your &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes&quot;&gt;ISO 3166 country code&lt;/a&gt; (for the United States this will be &lt;code&gt;US&lt;/code&gt; without quotes). Update the &lt;code&gt;ssid&lt;/code&gt; and &lt;code&gt;psk&lt;/code&gt; lines of the &lt;code&gt;network&lt;/code&gt; section to your Wi-Fi network SSID and password, with quotes. Read more about setting up Wi-Fi &lt;a href=&quot;https://www.raspberrypi.org/documentation/configuration/wireless/headless.md&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My &lt;code&gt;wpa_supplicant.conf&lt;/code&gt; might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-conf&quot;&gt;ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
update_config=1
country=US

network={
    ssid=&amp;quot;patricknet&amp;quot;
    psk=&amp;quot;myverysecurepassword&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Note on Text Encoding&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.raspberrypi.org/documentation/configuration/wireless/headless.md&quot;&gt;Setting up a Raspberry Pi headless&lt;/a&gt;: ‚ÄúDepending on the OS and editor you are creating this on, the file could have incorrect newlines or the wrong file extension so make sure you use an editor that accounts for this. Linux expects the line feed (LF) newline character.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn More: &lt;a href=&quot;https://www.youtube.com/watch?v=TtiBhktB4Qg&quot;&gt;Scott Hanselman on CR/LF&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;2. Set up Wi-Fi:&lt;/strong&gt; Create a &lt;code&gt;wpa_supplicant.conf&lt;/code&gt; file in the root directory of the SD card, and populate it with your Wi-Fi credentials to enable Wi-Fi on boot. &lt;a href=&quot;https://www.raspberrypi.org/documentation/configuration/wireless/headless.md&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;3. Set up SSH&lt;/h3&gt;
&lt;p&gt;By default SSH access is disabled on a Raspberry Pi, the usual way of enabling it is either through the GUI or &lt;code&gt;raspi-config&lt;/code&gt;, but there is also a simple way to pre-setup on the SD card. Create an empty file called &lt;code&gt;ssh&lt;/code&gt; (without a file extension) in the root directory of the SD card, this will enable SSH on boot.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;3. Set up SSH:&lt;/strong&gt; Create an empty &lt;code&gt;ssh&lt;/code&gt; file in the root directory of the SD card to enable SSH access on boot. &lt;a href=&quot;https://www.raspberrypi.org/documentation/remote-access/ssh/README.md&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Raspberry Pi Setup&lt;/h2&gt;
&lt;p&gt;You are now ready to boot the Raspberry Pi, insert the SD card and power up the Pi. After a minute or two of boot time it should automatically connect to your network.&lt;/p&gt;
&lt;h3&gt;4. Connect via SSH&lt;/h3&gt;
&lt;p&gt;In a terminal on a second computer and connect to the Raspberry Pi via SSH. The default username and password will be &lt;code&gt;pi&lt;/code&gt; and &lt;code&gt;raspberry&lt;/code&gt;, and the default hostname will be &lt;code&gt;raspberrypi&lt;/code&gt;. If your local network supports the &lt;code&gt;.local&lt;/code&gt; TLD you may be able to connect using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ssh pi@raspberrypi.local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Otherwise you will need to look up the IP address of the Pi in your network admin tools and connect using the IP address:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ssh pi@192.168.XXX.XXX
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also skip this step and open the Terminal app on the Pi if using a display and keyboard connected to the Pi.&lt;/p&gt;
&lt;p&gt;If you have previously connected via SSH to a Raspberry Pi with the default hostname on the computer you are using you may see a message about the remote host identification changing. To successfully connect via SSH you will need to update the &lt;code&gt;known_hosts&lt;/code&gt; file to remove the key stored for the other Raspberry Pi.&lt;/p&gt;
&lt;p&gt;On Linux or macOS the &lt;code&gt;known_hosts&lt;/code&gt; file will be at &lt;code&gt;/Users/[YOUR USERNAME]/.ssh/known_hosts&lt;/code&gt;. Find the line in this file that starts with either &lt;code&gt;raspberrypi.local&lt;/code&gt; or the Raspberry Pi‚Äôs IP address and remove it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;4. Connect via SSH:&lt;/strong&gt; Connect to the Raspberry Pi via ssh: &lt;code&gt;ssh pi@raspberrypi.local&lt;/code&gt; or &lt;code&gt;ssh pi@192.168.XXX.XXX&lt;/code&gt; (and enter the default password &lt;code&gt;raspberry&lt;/code&gt;). You may need to remove a previous &lt;code&gt;raspberrypi.local&lt;/code&gt; from &lt;code&gt;/Users/USERNAME/.ssh/known_hosts&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;5. Change the Password&lt;/h3&gt;
&lt;p&gt;After connecting to the Raspberry Pi via SSH the login message will suggest that you change the default password:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;SSH is enabled and the default password for the &#39;pi&#39; user has not been changed.&lt;/code&gt; &amp;gt; &lt;code&gt;This is a security risk - please login as the &#39;pi&#39; user and type &#39;passwd&#39; to set a new password.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Following the instructions you can type &lt;code&gt;passwd&lt;/code&gt; which will prompt you first for your current password (&lt;code&gt;raspberry&lt;/code&gt;), then for a new password twice.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;5. Change the password:&lt;/strong&gt; Run &lt;code&gt;passwd&lt;/code&gt; to have the system prompt you for a new, more secure password.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;6. Change the Hostname&lt;/h3&gt;
&lt;p&gt;The default hostname of your Raspberry Pi is &lt;code&gt;raspberrypi&lt;/code&gt;. You may want to change this for a few reasons. If you have more than one Raspberry Pi on your network this will let you tell them apart, and if your network supports the .local TLD you can use the hostname as the URL to your app.&lt;/p&gt;
&lt;p&gt;You will need to update two files to change your hostname. First open &lt;code&gt;/etc/hostname&lt;/code&gt; and change the first and only line in the file (currently &lt;code&gt;raspberrypi&lt;/code&gt;) to your new hostname. Then, open &lt;code&gt;/etc/hosts&lt;/code&gt; and update the the line with &lt;code&gt;raspberrypi&lt;/code&gt; to your new hostname. Finally, reboot your Pi for the changes to take effect. Remember, if you SSHed in as &lt;code&gt;pi@raspberrypi.local&lt;/code&gt; you will need to use the new hostname instead.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;6. Change the Hostname:&lt;/strong&gt; Open &lt;code&gt;sudo nano /etc/hostname&lt;/code&gt; and change &lt;code&gt;raspberrypi&lt;/code&gt; to your new hostname, then &lt;code&gt;sudo nano /etc/hosts&lt;/code&gt; and change &lt;code&gt;raspberrypi&lt;/code&gt; to your new hostname. Then reboot, &lt;code&gt;sudo reboot now&lt;/code&gt;. &lt;a href=&quot;https://pimylifeup.com/raspberry-pi-hostname/&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;7. Change the Prompt&lt;/h3&gt;
&lt;p&gt;I also like the change the default bash prompt whenever I am going to be SSHing into a remote computer so that I can tell the difference at a glance between a local and remote terminal window.&lt;/p&gt;
&lt;p&gt;A simple change is just to prepend an emoji to the default prompt, which you can do by adding a line to &lt;code&gt;~/.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;echo &#39;PS1=&amp;quot;ü•ß ${PS1}&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I like the following prompt which adds colors that are different than the ones that I use locally, and a pie emoji:&lt;/p&gt;
&lt;div class=&quot;fake-code&quot;&gt;
&lt;span style=&quot;color: white; background-color: silver;&quot;&gt;&amp;nbsp;Mon May &amp;nbsp;03 23:41:09&amp;nbsp;&lt;/span&gt;&lt;br /&gt;
&lt;span style=&quot;color: black; background-color: cyan;&quot;&gt;&amp;nbsp;pi@b:&amp;nbsp;&lt;/span&gt; &lt;span style=&quot;color: white; background-color: lightGrey;&quot;&gt;&amp;nbsp;~&amp;nbsp;&lt;/span&gt;&lt;br /&gt;
ü•ß $&lt;br /&gt;
&lt;/div&gt;
&lt;p&gt;Update your prompt by editing your &lt;code&gt;~/.bashrc&lt;/code&gt; file with &lt;code&gt;sudo nano ~/.bashrc&lt;/code&gt;. The bash prompt is set with the &lt;code&gt;PS1&lt;/code&gt; variable, which has two versions in the default Raspberry Pi &lt;code&gt;~/.bashrc&lt;/code&gt;, one for when &lt;code&gt;color_prompt&lt;/code&gt; is set to &lt;code&gt;yes&lt;/code&gt;, another for otherwise. The default in Raspberry Pi OS is that &lt;code&gt;color_prompt&lt;/code&gt; is set to yes, so feel free to overwrite only the first &lt;code&gt;PS1&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;The value to set the prompt I showed above is (the sections with &lt;code&gt;[\033 ...&lt;/code&gt; and &lt;code&gt;\[$(tput...&lt;/code&gt; control turning on and off the colors):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PS1=&amp;quot;\n\[\033[48;5;7m\] \d \t \[$(tput sgr0)\]\n\[$(tput bold)\]\[\033[38;5;0m\]\[\033[48;5;14m\] \u@\H: \[$(tput sgr0)\] \[\033[38;5;0m\]\[\033[48;5;15m\] \w \[$(tput sgr0)\]\n ü•ß \\$ &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run &lt;code&gt;source ~/.bashrc&lt;/code&gt; (or &lt;code&gt;. ~/.bashrc&lt;/code&gt;) to reload your terminal and see your new prompt.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;7. Change the Prompt:&lt;/strong&gt; Update the &lt;code&gt;PS1&lt;/code&gt; variable in &lt;code&gt;~/.bashrc&lt;/code&gt; to make it look different. Add a pie emoji with &lt;code&gt;echo &#39;PS1=&amp;quot;ü•ß ${PS1}&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bashrc&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Install Git&lt;/h3&gt;
&lt;p&gt;You will probably want to use Git to manage the source code for your app. It is not installed by default on Raspberry Pi OS so you will need to install it now with &lt;code&gt;apt&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo apt install git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: You may have to update by running &lt;code&gt;sudo apt-get update&lt;/code&gt; in order for Git to install.&lt;/p&gt;
&lt;p&gt;You may also want to install another text editor if you want something more customizable than nano.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;8. Install Git:&lt;/strong&gt; Install git to manage your source code with &lt;code&gt;sudo apt install git&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;9. Install Nginx&lt;/h2&gt;
&lt;p&gt;You can now run a webserver (with &lt;code&gt;sudo&lt;/code&gt;) on port 80 and have it be available at your IP address or &lt;code&gt;[YOUR_HOSTNAME].local&lt;/code&gt;, but that might require more configuration. It will be easier to manage your app if you install a webserver/reverse proxy like Nginx. You can install Nginx with &lt;code&gt;apt&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo apt install nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once Nginx is installed you should be able to access the default Nginx webpage at your Rapsberry Pi‚Äôs IP Address or &lt;code&gt;[YOUR_HOSTNAME].local&lt;/code&gt;. Make sure to type in the &lt;code&gt;http://&lt;/code&gt; the first time if you are using the &lt;code&gt;.local&lt;/code&gt; TLD to avoid triggering search in your browser.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/how-to-raspberry-pi-server/nginx-default.png&quot; alt=&quot;A screenshot of the default Nginx page&quot; /&gt;&lt;/p&gt;
&lt;p&gt;You can now serve any static website from &lt;code&gt;/var/www/html&lt;/code&gt;, if you look there you will see an &lt;code&gt;index.html&lt;/code&gt; or &lt;code&gt;index.nginx-debian.html&lt;/code&gt; file that is generating the current page.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;9. Install Nginx:&lt;/strong&gt; Install with &lt;code&gt;apt install nginx&lt;/code&gt;, then put a static webpage in &lt;code&gt;/var/www/html&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;10. Install nvm and npm&lt;/h2&gt;
&lt;p&gt;I make most of my web apps these days in JavaScript, there are lots of ways to install node and npm, but one easy way to manage versions is with nvm, which can be installed with the script below:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then reload your terminal with &lt;code&gt;. ~/.bashrc&lt;/code&gt; and install the current LTS version of node with &lt;code&gt;nvm install lts&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; On an original Raspberry Pi, or a Raspberry Pi Zero, the ARMv6 chip is no longer supported by current versions of node. ‚ÄúUnofficial‚Äù ARMv6 builds of node are available at: &lt;a href=&quot;https://unofficial-builds.nodejs.org/&quot;&gt;unofficial-builds.nodejs.org&lt;/a&gt;. To install a version using an unofficial build use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;NVM_NODEJS_ORG_MIRROR=https://unofficial-builds.nodejs.org/download/release nvm install lts
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;10. Install nvm and npm:&lt;/strong&gt; &lt;code&gt;curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash&lt;/code&gt;, &lt;code&gt;. ~/.bashrc&lt;/code&gt;, &lt;code&gt;nvm install lts&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;11. Set Up Reverse Proxy&lt;/h2&gt;
&lt;p&gt;In order to access your app on your local network without a port number in the URL it will need to be accessible on port 80, but it will be eaiser to run your app on another port locally. This can be done with an Nginx reverse proxy.&lt;/p&gt;
&lt;p&gt;Nginx cofiguration is done via server block files, you can delete the default enabled server block by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo rm /etc/nginx/sites-enabled/default
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, make your own empty server block in the &lt;code&gt;sites-available&lt;/code&gt; directory: . The &lt;code&gt;[YOUR SITE]&lt;/code&gt; part of the path can be anything, but it makes sense to give it the name of your app.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo touch /etc/nginx/sites-available/[YOUR SITE].conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now edit your server block file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo nano /etc/nginx/sites-available/[YOUR SITE].conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The server block below will proxy processes running on port 8080 to port 80 (but you can substitute any port on the &lt;code&gt;proxy_pass&lt;/code&gt; line). Make sure to replace the &lt;code&gt;[HOSTNAME]&lt;/code&gt; sections with your Raspberry Pi‚Äôs hostname (or omit this line if accessing via IP Address):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-conf&quot;&gt;server {
    listen 80;
    server_name www.[HOSTNAME].local [HOSTNAME].local;

    location / {
       proxy_pass http://127.0.0.1:8080;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, link your Nginx config file to the &lt;code&gt;sites-enabled&lt;/code&gt; directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo ln -s /etc/nginx/sites-available/[YOUR-SITE].conf /etc/nginx/sites-enabled/[YOUR-SITE].conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test your Nginx config with &lt;code&gt;sudo nginx -t&lt;/code&gt;. You should see a success confirmation message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To enable the configuration reload the Nginx config:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo systemctl reload nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last step is cloning your project to the Raspberry Pi and running it on port 8080, your app should now be available at &lt;code&gt;[HOSTNAME].local&lt;/code&gt;!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;11. Set Up Reverse Proxy:&lt;/strong&gt; Remove default: &lt;code&gt;sudo rm /etc/nginx/sites-enabled/default&lt;/code&gt;, Create config file: &lt;code&gt;sudo touch /etc/nginx/sites-available/[YOUR SITE].conf&lt;/code&gt;, Edit config file (see above): &lt;code&gt;sudo nano /etc/nginx/sites-available/[YOUR SITE].conf&lt;/code&gt;, Link to sites-enabled: &lt;code&gt;sudo ln -s /etc/nginx/sites-available/[YOUR-SITE].conf /etc/nginx/sites-enabled/[YOUR-SITE].conf&lt;/code&gt;, Reload Nginx: &lt;code&gt;sudo systemctl reload nginx&lt;/code&gt;. &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-debian-10&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/how-to-raspberry-pi-server/hello-world.png&quot; alt=&quot;A screenshot of a ‚ÄúHello, World‚Äù page hosted on a Raspberry Pi&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;All Steps:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Install the OS:&lt;/strong&gt; Use Raspberry Pi Imager tool to write the OS to the SD card &lt;a href=&quot;https://www.raspberrypi.org/software/&quot;&gt;source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set up Wi-Fi:&lt;/strong&gt; Create a &lt;code&gt;wpa_supplicant.conf&lt;/code&gt; file in the root directory of the SD card, and populate it with your Wi-Fi credentials to enable Wi-Fi on boot. &lt;a href=&quot;https://www.raspberrypi.org/documentation/configuration/wireless/headless.md&quot;&gt;source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set up SSH:&lt;/strong&gt; Create an empty &lt;code&gt;ssh&lt;/code&gt; file in the root directory of the SD card to enable SSH access on boot. &lt;a href=&quot;https://www.raspberrypi.org/documentation/remote-access/ssh/README.md&quot;&gt;source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connect via SSH:&lt;/strong&gt; Connect to the Raspberry Pi via ssh: &lt;code&gt;ssh pi@raspberrypi.local&lt;/code&gt; or &lt;code&gt;ssh pi@192.168.XXX.XXX&lt;/code&gt; (and enter the default password &lt;code&gt;raspberry&lt;/code&gt;). You may need to remove a previous &lt;code&gt;raspberrypi.local&lt;/code&gt; from &lt;code&gt;/Users/USERNAME/.ssh/known_hosts&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change the password:&lt;/strong&gt; Run &lt;code&gt;passwd&lt;/code&gt; to have the system prompt you for a new, more secure password.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change the Hostname:&lt;/strong&gt; Open &lt;code&gt;sudo nano /etc/hostname&lt;/code&gt; and change &lt;code&gt;raspberrypi&lt;/code&gt; to your new hostname, then &lt;code&gt;sudo nano /etc/hosts&lt;/code&gt; and change &lt;code&gt;raspberrypi&lt;/code&gt; to your new hostname. Then reboot, &lt;code&gt;sudo reboot now&lt;/code&gt;. &lt;a href=&quot;https://pimylifeup.com/raspberry-pi-hostname/&quot;&gt;source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change the Prompt:&lt;/strong&gt; Update the &lt;code&gt;PS1&lt;/code&gt; variable in &lt;code&gt;~/.bashrc&lt;/code&gt; to make it look different. Add a pie emoji with &lt;code&gt;echo &#39;PS1=&amp;quot;ü•ß ${PS1}&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bashrc&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Git:&lt;/strong&gt; Install git to manage your source code with &lt;code&gt;sudo apt install git&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Nginx:&lt;/strong&gt; Install with &lt;code&gt;apt install nginx&lt;/code&gt;, then put a static webpage in &lt;code&gt;/var/www/html&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install nvm and npm:&lt;/strong&gt; &lt;code&gt;curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash&lt;/code&gt;, &lt;code&gt;. ~/.bashrc&lt;/code&gt;, &lt;code&gt;nvm install lts&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set Up Reverse Proxy:&lt;/strong&gt; Remove default: &lt;code&gt;sudo rm /etc/nginx/sites-enabled/default&lt;/code&gt;, Create config file: &lt;code&gt;sudo touch /etc/nginx/sites-available/[YOUR SITE].conf&lt;/code&gt;, Edit config file (see above): &lt;code&gt;sudo nano /etc/nginx/sites-available/[YOUR SITE].conf&lt;/code&gt;, Link to sites-enabled: &lt;code&gt;sudo ln -s /etc/nginx/sites-available/[YOUR-SITE].conf /etc/nginx/sites-enabled/[YOUR-SITE].conf&lt;/code&gt;, Reload Nginx: &lt;code&gt;sudo systemctl reload nginx&lt;/code&gt;. &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-debian-10&quot;&gt;source&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
  </entry>
  
  <entry>
    <title>Alphabetic Internet Time: A Time Zone for the Internet</title>
    <link href="https://patrickweaver.net/blog/alphabetic-internet-time/"/>
    <updated>2022-08-18T00:00:00Z</updated>
    <id>https://patrickweaver.net/blog/alphabetic-internet-time/</id>
    <content type="html">&lt;p&gt;In the Fall of 2020 I &lt;a href=&quot;https://www.patrickweaver.net/blog/a-recurse-center-remote-batch/&quot;&gt;participated in a 12 week batch&lt;/a&gt; at the &lt;a href=&quot;https://recurse.com/&quot;&gt;Recurse Center&lt;/a&gt;. While I had a lot of previous experience &lt;em&gt;working&lt;/em&gt; remotely, both before and during the pandemic, RC was the first time where I was communicating with people in more than 1 or 2 other time zones. I now work at a fully remote company, mostly spread over the 4(ish) U.S. time zones, but with a few people permanently or temporarily in other places.&lt;/p&gt;
&lt;h2&gt;Communicating across time zones&lt;/h2&gt;
&lt;p&gt;RC when I was there (mostly I would guess because their software was designed and configured for in person retreats in NYC) operated for the most part in Eastern Time, although I see from my limited participation in the community as an alum that this may have shifted, especially thanks to &lt;a href=&quot;https://zulip.com/help/format-your-message-using-markdown#global-times&quot;&gt;Zulip‚Äôs time-zone-relative timestamp support&lt;/a&gt;. RC had transitioned to hosting Recursers remotely a few months before my batch, which is how they continue to operate now in Summer 2022. At my current job we often default to either Eastern Time or Pacific Time, but some people will also just use their local time and let others figure it out.&lt;/p&gt;
&lt;p&gt;Out of politeness and miscalculation-anxiety reducing redundancy I often will use multiple time zones, for example when proposing a meeting I might say, &lt;em&gt;‚ÄúLet‚Äôs meet at üóΩ 12:30 PM ET / üèî 10:30 AM MT / üåÅ 9:30 AM PT,‚Äù&lt;/em&gt; (I‚Äôm still searching for a good Central Time emoji, üõ£ üåΩ üå™ are the best I&#39;ve got), but time zone based confusion often takes more thinking than it should.&lt;/p&gt;
&lt;p&gt;(Side note, it bewilders me that Slack still doesn‚Äôt have something similar to Zulip‚Äôs &lt;em&gt;‚Äúyou write in your time zone, they read in their time zone‚Äù&lt;/em&gt; timestamp support in 2022. üôÉ)&lt;/p&gt;
&lt;h2&gt;Time zones are pretty confusing, DST makes them worse&lt;/h2&gt;
&lt;p&gt;Something that probably doesn‚Äôt cause very much confusion for most other people, but I can‚Äôt help but consistently notice is that most people exclusively use ‚ÄùEST/CST/MST/PST‚Äù throughout the year, even during the Spring, Summer, and Fall, when most of the U.S. is observing Daylight Saving Time. This linguistic pattern (which I assume is somewhat caused by ‚ÄúEST‚Äù seeming like an abbreviation for ‚ÄúEastern‚Äù) makes me especially curious what the commonly used abbreviations will be if the U.S. &lt;a href=&quot;https://web.archive.org/web/20220315222718/https://www.nytimes.com/2022/03/15/us/politics/daylight-saving-time-senate.html&quot;&gt;switches to permanent DST&lt;/a&gt;, and how people in Arizona, &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_in_Arizona&quot;&gt;which mostly does not observe DST&lt;/a&gt; understand someone in Denver saying, ‚ÄúLet‚Äôs meet at 10:30 MST on August 14.‚Äù I would imagine them thinking something like, ‚Äùüò´.‚Äù&lt;/p&gt;
&lt;p&gt;Even Google search seems to get this wrong as searching &lt;a href=&quot;https://google.com/search?q=current%20time%20MST&quot;&gt;‚Äúcurrent time MST‚Äù&lt;/a&gt; at 8:39 PM EDT in NYC in August shows ‚Äù6:39 Mountain Time (MT)‚Äù, though I also wonder what the same search would show in Arizona.&lt;/p&gt;
&lt;h2&gt;A time zone for the internet&lt;/h2&gt;
&lt;p&gt;All of this leads to my Alphabetic Internet Time (AIT), which I consider &lt;em&gt;‚ÄúA Great Idea That Will Never Work.‚Äù&lt;/em&gt; AIT is essentially UTC, but with the letters A through X of the (English) alphabet replacing the hour digits. Midnight UTC is A:00, Noon UTC is M:00, 1:34 PM UTC is N:34. Just like UTC, these times are not local, S:00 is the same moment everywhere (18:00 UTC). For someone in New York in August 2022 observing EDT, it is 2:00 PM, for the same person in January 2023 S:00 is 1:00 PM. For someone in San Francisco in August, S:00 is 11:00 AM.&lt;/p&gt;
&lt;p&gt;This may all sound confusing, but it‚Äôs mostly because AIT is not really useful at all for knowing what time it is somewhere else. The main goal of AIT is reducing the amount of time you spend thinking about what time it is somewhere else (though it is likely still polite to make sure you‚Äôre not trying to schedule something in the middle of someone else‚Äôs night). AIT starts to make sense when you think about people in different time zones communicating about something that will happen online. As someone who works normal business hours in NYC, my work day goes from N:00 (9 AM EDT) to V:00 (5 PM EDT), with lunch usually at Q:30 (though during the Winter it would be O:00 to W:00). If I‚Äôm planning with someone in San Francisco who also works normal business hours (Q:00 - A:00) and we want at least an hour, we could easily see that any time between R:00 and V:00 would work, and we would both know what time that was for us.&lt;/p&gt;
&lt;p&gt;If AIT were to work it wouldn‚Äôt rely on people manually calculating the current time, they would need clocks that display AIT like this reference implementation I made: &lt;a href=&quot;https://doodles.patrickweaver.net/ait/&quot; target=&quot;_blank&quot;&gt;doodles.patrickweaver.net/ait/&lt;/a&gt;&lt;/p&gt;
&lt;figure style=&quot;text-align: center; width: 100%;&quot;&gt;
  &lt;iframe id=&quot;ait-clock&quot; style=&quot;border: 1px solid black; margin: 1rem auto;&quot; title=&quot;Alphabetic Internet Time Clock&quot; width=&quot;400&quot; height=&quot;400&quot; src=&quot;https://doodles.patrickweaver.net/ait/&quot;&gt;
  &lt;/iframe&gt;
  &lt;figcaption&gt;A reference implementation of an AIT clock at: &lt;a href=&quot;https://doodles.patrickweaver.net/ait/&quot; target=&quot;_blank&quot;&gt;doodles.patrickweaver.net/ait/&lt;/a&gt; &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2&gt;Why not just use UTC?&lt;/h2&gt;
&lt;p&gt;People who are already used to using UTC might look at AIT and think that it‚Äôs just a confusing extra layer on top of a system that works pretty well, but in my opinion, moving whole communities of people to UTC would likely be very difficult because doing so asks them to do the same mental math as coordinating between time zones, but often with larger numbers.&lt;/p&gt;
&lt;p&gt;Even after changing my phone to use a 24 hour clock for weeks while spending time in countries where that is common I still found myself translating 16:00 to &lt;em&gt;‚Äú16 - 2 - 10 = 4 PM‚Äù&lt;/em&gt; in my head. My guess is that for most people it would be easier to convert between two separate concepts, their local time with numbers, and AIT with letters, but I may be wrong. The other advantage is clarity, even if the known best practice is to use UTC, a message like ‚ÄúLet‚Äôs meet at 15:30‚Äù can still be unclear, potentially UTC, the sender‚Äôs local time, or your own!&lt;/p&gt;
&lt;h2&gt;Does anything like this exist?&lt;/h2&gt;
&lt;p&gt;The closest thing to AIT that currently exists is the &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_military_time_zones&quot;&gt;Military Time Zones&lt;/a&gt; which also use the alphabet to refer to time zones, but in a way that doesn‚Äôt make much sense. Like AIT the time zones move East from UTC with UTC+1 being ‚ÄúAlfa‚Äù, UTC+2 ‚ÄúBravo‚Äù, and continuing through the NATO phonetic alphabet (though skipping ‚ÄúJuliett‚Äù) to UTC+12, ‚ÄúMike‚Äù. However, rather than continue through the alphabet at UTC-11, ‚ÄúNovember‚Äù is back near where we started as UTC-1 (and continues moving West from there).&lt;/p&gt;
&lt;p&gt;The military time zone names do seem useful, and are possibly too similar to AIT for my idea to catch on, but out of sequence order make the concept seem too confusing for anyone using it for much beyond just ‚Äútime zone names.‚Äù&lt;/p&gt;
&lt;p&gt;One interesting (and further confusing thing) about the military time zone names is that ‚ÄúMike‚Äù, UTC+12 and ‚ÄúYankee‚Äù, UTC-12 are the same time, but on different dates because the border straddles the international date line. It‚Äôs quirks like this that make me think that any improvement on time zone related communication is likely to fail.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/ait/military-time-zones.png&quot; alt=&quot;A map of military time zones from the ACP 121(I) standard&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Reasons why AIT will never work&lt;/h2&gt;
&lt;p&gt;As good an idea as I think this is, I have no hopes of AIT catching on mostly because I think that most people wouldn‚Äôt be able to get over the ridiculousness of saying ‚ÄúM:45‚Äù (and not being worried people would think they‚Äôre talking about a bus). But beyond the silliness, it‚Äôs still Daylight Saving Time that makes communicating across time zones unlikely to be improved on.&lt;/p&gt;
&lt;p&gt;If your own time zone stayed the same relative to AIT year round I think there would be a chance that, with tools like an AIT display next to your local time, or calendar integrations, that it would work for a lot of people who frequently communicate with people in other time zones, but having to switch recurring times back and forth by one letter twice a year seems like friction that would dampen most people‚Äôs enthusiasm.&lt;/p&gt;
&lt;p&gt;Bringing dates into the picture also seems like it would complicate things. Even though A:15 is 5:15 PM PDT in San Francisco, if we put a date on it, it would have to be ‚Äútomorrow‚Äù for the person in SF to match UTC. I don‚Äôt think that this would add any additional confusion to communicating with people whose time zone is in the next day relative to your own, but a new system like AIT would likely get blamed for the inherent awkwardness of time zones.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://patrickweaver.net/images/blog/ait/sf-ny-sunset.jpg&quot; alt=&quot;Photographs of the sunset in San Francisco, CA, and New York, NY&quot; /&gt;&lt;/p&gt;
&lt;p&gt;But who knows! Weirder ideas have caught on in the past, like Daylight Saving Time! Or, maybe we can all just join the UTC+8 ‚ÄúHotel‚Äù time zone since almost 25% of the world population already lives in it!&lt;/p&gt;
&lt;p&gt;Aug 18, 2022 B:14, Brooklyn, NY&lt;/p&gt;
</content>
  </entry>
</feed>